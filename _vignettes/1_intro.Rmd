---
title: 'Introduction to scRNAseq analysis'
date: "August 12<sup>th</sup>, 2019"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
---

```{r "knitr options", echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  collapse = TRUE,
  echo = FALSE,
  cache = FALSE,
  comment = "#>",
  fig.align = "center"
)
```

## intro to RBI
__rbi.fellows@ucdenver.edu__, 

RC1 South room 9101

[office hours on Thursdays](https://rnabioco.github.io/rbi-project-summary/office-hours.html)

## outline of the workshop
* Prereq: check all required packages are installed
* Day 1 (pm):
  + Intro to scRNAseq
  + Data preprocessing
  + Import into R
  + Quality control

* Day 2 (am):
  + Projections
  + Clustering
  + Finding markers
  + Annotating cell types

* Day 2 (pm):
  + Pseudotime analysis
  + Dataset alignment

* Day 3 (am):
  + Multimodal data (CITE-seq, hashing)
  + Miscellaneous

* Day 3 (pm) : working through your own data
* Survey after the workshop for feedback

## limitations of scRNAseq
![from seurat pbmc example](1_intro_files2/cd4vs8.png){width=800px}

1. dropout effect, only a small portion of the mRNAs from each cell is captured (see: GFP and other supposed markers)

2. low number of detectable genes, might not detect low expressing genes at all (see: TFs)

3. little info outside of gene counts (see: tail-seq, isoform info)

4. discrepancies between RNA and protein, especially surface proteins (see: CD4+ vs CD8+)

5. constantly evolving chemistry and bioinformatics tools (see: 10x v2/v3/v3.1, [bad cell calling in cellrangerV2](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/algorithms/overview#cell_calling))

## experimental design >> informatics corrections
![cell isolation process for 10x](1_intro_files2/10xV3_model.png){width=400px}

1. too few or too many cells - 1000 cell lower limit for capture, and waste of money

2. doublets - 10000 cells ~ 10% doublet rate  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(try: [scrublet](https://github.com/AllonKleinLab/scrublet))

3. cell death - worse RNA capture, potentially different expression profile  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(try: MT-RNA cutoff, regress out MT-RNA score)

4. lysed/free RNA - background for all cells, interferes with clustering and markers  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(try: [SoupX](https://github.com/constantAmateur/SoupX))

![example data with lyzed red blood cells](1_intro_files2/contaminant.png){width=800px}

5. different sex of mice in samples - makes sample comparisons harder  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(try: ignore known sex-dependent genes)

6. batch effects - still preferrable to have all, or at least the direct comparison samples, captured at the same time  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(try: various alignment methods)

7. n = ? - no consensus in the field, but aggregating 2 or more biological repeats, or hash multiple samples at the same time, should be valid

## single cell RNA sequencing overview
cell suspension -> cDNA library -> fastq file -> gene expression matrix -> 

&nbsp;&nbsp;&nbsp;&nbsp;filtering -> preprocessing -> dimension reduction -> clustering -> identity and markers -> pseudotime

### 1. sequencing methods
main platforms: 10x vs Smart-seq2 vs sci-RNA-seq3

```{r table1, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tab <- "
|method        |cell isolation      |coverage       |saturation read # |gene detection  |throughput and cost        |
|--------------|--------------------|---------------|------------------|----------------|---------------------------|
|10x Chromium  |droplet-based       |polyA+ 3' only |10^5 per cell     |~2000 per cell  |~5k cells, low cost        |
|Smart-seq2    |FACS-sorted         |full length    |10^6 per cell     |~4000 per cell  |manual pipetting, high cost|
|sci-RNA-seq3   |combinatorial index |polyA+ 3' only |10^5 per cell     |~1000 per cell  |~1m cells, lowest cost     |
"
cat(tab)
```

variations within 10x system: standard 3', 5' + V(D)J, hashing, CITE-seq, variant-calling (very different sample prep, may require up to 4 library preps per sample)

### 2. alignment pipelines
[cellranger](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/installation) (alternatives such as [Alevin](https://salmon.readthedocs.io/en/latest/alevin.html), [STARsolo](https://github.com/alexdobin/STAR/releases), [Kallisto](https://www.kallistobus.tools/))
```{r, engine = 'bash', eval = FALSE, echo = T}
# in terminal
cellranger count --id=123 \
                 --transcriptome=/refdata-cellranger-GRCh38-3.0.0 \
                 --fastqs=/home/runs/HAT7ADXX/outs/fastq_path \
                 --sample=mysample
```
~ 5-8 hours per sample on biochem department cluster Bodhi

theoretically can be ran locally on linux, but will require at least 32GB of RAM

other campus options include Rosalind, AWS

cellranger output [html](http://cf.10xgenomics.com/samples/cell-exp/3.1.0/5k_pbmc_protein_v3/5k_pbmc_protein_v3_web_summary.html) and [loupe](http://cf.10xgenomics.com/samples/cell-exp/3.1.0/5k_pbmc_protein_v3/5k_pbmc_protein_v3_cloupe.cloupe) files

### 3. key things to check for in the initial output
1. number of cells close to expectations? Is the elbow plot reasonable?
2. reads per cell (this is merely calculated as reads/cells, so somewhat inaccurate) - ideally ~50-100k, 
3. genes per cell, ideally ~2000
4. sequencing saturation?
5. any structure in the dimension reduction tSNE?

### 4. downstream processing in R or python
1. more accurate cell calling
2. more stringent filtering
3. regress out unwanted sources of variance
4. appropriate choice of normalization method
5. UMAP instead of tSNE projections, and fine-tuning
6. fine-tuning of dataset alignment methods and parameters (by default cellranger does align during aggregation)
7. find marker genes and assign cluster identities (may merge some)
8. more flexible visualizations
9. GO term analysis and other things
10. export to a hosted browser, similar to cloupe

## reading and making UMI-barcode elbow plots
![model of final 10x library](1_intro_files2/10xV3_seq.png){width=400px}

The total UMI (unique molecular identifier - present each transcript) of a cell barcode is used to rank the barcodes determine the UMI threshold for signal vs noise. A plot is generated for cellranger html output, but can be useful in other situations like bashing and CITE-seq.

for a standard scRNAseq run:

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expected range of x axis (barcode) : > 10^5 (if using ggplot to visuualize, might want to filter) 
  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expected inflection point of x axis (cell number): ~ # of loaded cells / 2
  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expected range of y axis (UMI_counts) : > 10^4
  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expected inflection point of y axis (cutoff UMI count): >= 1000
  
```{r, fig.width=6, fig.height=3, echo = T}
library(tidyverse)
m1 <- readRDS("1_intro_files2/raw_matrix1.rds")
m2 <- readRDS("1_intro_files2/raw_matrix2.rds")

# gene x barcodes
print(dim(m1))
print(dim(m2))

counts <- Matrix::colSums(m1) # calculate total UMI read number for each cell barcode
countdf <- as.data.frame(counts) %>% 
  as_tibble(rownames = "barcode") %>% 
  filter(counts >= 2) %>% # throw out cell barcodes with 1 or less UMI, this is mainly for time purposes
  arrange(desc(counts)) %>% # arrange by descending order
  mutate(n = 1:n()) # rank

g1 <- ggplot(countdf, aes(x = n, y = counts)) +
  geom_point() +
  labs(x = "barcodes", y = "UMI_counts") +
  theme_classic() +
  scale_x_log10() + 
  scale_y_log10()

counts2 <- Matrix::colSums(m2)
countdf2 <- as.data.frame(counts2) %>%
  as_tibble(rownames = "barcode") %>% 
  filter(counts2 >= 2) %>%
  arrange(desc(counts2)) %>%
  mutate(n = 1:n())

g2 <- ggplot(countdf2, aes(x = n, y = counts2)) +
  geom_point() +
  labs(x = "barcodes", y = "UMI_counts") +
  theme_classic() +
  scale_x_log10() + 
  scale_y_log10()

cowplot::plot_grid(g2, g1, nrow = 1, labels = c("good", "bad"))
```

## briefly, tidyverse/dplyr verbs
The tidyverse is a collection of R packages designed for data science. All packages share design philosophy, grammar, and data structures. 

Seurat also uses some of the grammar, such as `group.by`.

A large amount of code introduced in this workshop in based on matrix and dataframe manipulation. Therefore some basic understanding of tidyverse/dplyr will be helpful.

Also, "%>%" is used as "pipe", similar to unix `|`.
```{r}
# we will look at metadata from pbmc_small from Seurat
library(Seurat)
library(tidyverse)
# note that tidyverse is philosophically against rownames

meta <- pbmc_small@meta.data %>% as_tibble(rownames = "cell_id")
meta %>% head() %>% print() # <- same as print(head(meta))
```

```{r, echo = T}
# "select" certain columns of data
meta2 <- meta %>% select(cell_id, nCount_RNA, RNA_snn_res.0.8, letter.idents)
meta2 %>% head() %>% print()
```

```{r, echo = T}
# "filter" data to select specific rows
meta2 %>% filter(nCount_RNA >= 71, letter.idents == "A") %>% head() %>% print()
```

```{r, echo = T}
# "arrange" the rows of your data into an order
meta2 %>% arrange(nCount_RNA) %>% head() %>% print()
```

```{r, echo = T}
# "mutate" your data frame to contain new columns
meta3 <- meta2 %>% mutate(seurat_clusters = str_c("cluster_", letter.idents), 
                          nCount_RNA_norm = nCount_RNA/max(nCount_RNA))
meta3 %>% head() %>% print()
```

```{r, echo = T}
# "summarise" chunks of you data (by group) in some way.
meta3 %>% group_by(seurat_clusters) %>% summarize(n = n()) %>% head() %>% print()
```

## reading material
1. [Single-cell RNA sequencing technologies and bioinformatics pipelines](https://www.nature.com/articles/s12276-018-0071-8)
2. [Current best practices in single‐cell RNA‐seq analysis: a tutorial](https://www.embopress.org/doi/10.15252/msb.20188746)
3. ["Analysis of single cell RNA-seq data" course](https://scrnaseq-course.cog.sanger.ac.uk/website/index.html)
4. [Introduction to dplyr](https://dplyr.tidyverse.org/articles/dplyr.html)