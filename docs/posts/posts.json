[
  {
    "path": "posts/2021-10-14-r-installation/",
    "title": "R installation",
    "description": {},
    "author": [
      {
        "name": "Kent Riemondy",
        "url": "https://github.com/kriemo"
      }
    ],
    "date": "2021-10-27",
    "categories": [],
    "contents": "\nThis article will explain how to install R, Rstudio, and packages in R.If you are already familar with this material, skip to the Install packages for workshop section to see the packages that we will use in the workshop.\nDownload R\nDownload R from CRAN. Go to the cran homepage https://cran.r-project.org/. Select your operating system.\nMacOS\nSelect the newest R version, download the .pkg file, then open and install.\nWindows\nSelect the base link, then click download to download the .exe file. Open this file to install R.\nLinux\nIf you are on linux, then follow the documentation for your linux OS.\nDownload compiler tools\nMacOS\nYou may need to install the xcode command line tools if a package requires compilation. Open the Terminal from /Applications/Utilities/ (or use the search tool to search for terminal)\nType the following into Terminal:\nxcode-select --install\nPress “Install” and verify installation by typing into terminal:\ngcc --version\nWhich should print something similar to this:\n#' gcc (GCC) 4.8.5\n#' Copyright (C) 2015 Free Software Foundation, Inc.\n#' This is free software; see the source for copying conditions.  There is NO\n#' warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\nHere’s a youtube video explainer\nNext you need to install gfortran. Follow this link and go to the “INSTALL OS-SPECIFIC GFORTRAN BINARY” section. Select the download link based on your macOS version. This will supply an installer.\nWindows\nYou need to install Rtools from CRAN. Go to this link and download the exe installer for your OS: https://cran.r-project.org/bin/windows/Rtools/\nLinux\nYou probably have a compiler already?\nDownload Rstudio\nGo to the Rstudio website and download the installer for your OS.\nInstalling packages\nOnce you have R and Rstudio set up, open up rstudio, then we will install various packages.\nIn general there are 3 common places that you can get R packages from:\nCRAN, this is the official R package repository. CRAN has 16,000+ packages, including the tidyverse (ggplot2, dplyr, etc) and Seurat. Packages are installed using the install.packages() function. A successful install only needs to be done once.\nIn your console execute the following:\ninstall.packages(\"tidyverse\")\ninstall.packages(\"Seurat\")\nTest package installation once complete by loading the package(s)\nlibrary(tidyverse)\nlibrary(Seurat)\nBioconductor, which generally has bioinformatics related packages, such as clustifyr, DESeq2, ComplexHeatmap, etc.\nTo install bioconductor packages you should use the CRAN package BiocManager. BiocManager has a function called install() to install bioconductor packages. For example to install clustifyr\ninstall.packages(\"BiocManager\")\nlibrary(BiocManager)\ninstall(\"clustifyr\")\n# or equivalently you could run BiocManager::install(\"clustifyr\")\nGithub hosts open-source code from millions of projects. R packages hosted on github can be installed using the remotes package. Presto or djvdj are examples of single cell RNA-seq analysis packages on github. You’ll need to find the organization name and the repository name on github to install.\ninstall.packages(\"remotes\")\nremotes::install_github('rnabioco/djvdj')\nremotes::install_github('immunogenomics/presto')\nInstall packages for workshop\nWe will use the following packages:\nFrom CRAN:\n- tidyverse\n- Seurat\n- rmarkdown\n- cowplot\n- pheatmap\n- markdown\n\n\ninstall.packages(c('tidyverse',\n                   'rmarkdown',\n                   'Seurat',\n                   'cowplot',\n                   'pheatmap',\n                   'markdown'))\n\n\n\nFrom Bioconductor:\n- ComplexHeatmap\n- scran\n- scDblFinder\n- limma\n- clustifyr\n- slingshot\n- tradeSeq\n- clusterExperiment\n\n\nBiocManager::install(c('ComplexHeatmap', \n                       'scran',\n                       'scDblFinder',\n                       'limma',\n                       'clustifyr',\n                       'slingshot',\n                       'tradeSeq',\n                       'clusterExperiment'))\n\n\n\nFrom github:\n- destiny (hosted on bioconductor typically but not building correctly right now) - harmony (batch correction approach) - LaCroixColoR (pretty color palette)\n\n\nremotes::install_github('theislab/destiny')\nremotes::install_github('immunogenomics/harmony')\nremotes::install_github('johannesbjork/LaCroixColoR')\n\n\n\nTo test the installation, run the prerequisite Rmarkdown which will load all of these packages.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-28T15:08:58-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-26-class-3/",
    "title": "Batch correction and pseudotime",
    "description": "This tutorial walks through batch correction between two samples from different groups with some overlapping cell types using harmony. In the second half of the tutorial, we use timecourse data to run and evaluate pseudotime using slingshot.",
    "author": [
      {
        "name": "Kristen Wells",
        "url": "https://github.com/kwells4"
      }
    ],
    "date": "2021-10-26",
    "categories": [],
    "contents": "\n\nContents\nBackground\nDescription of dataDownload the files (Just an example, don’t run today)\nDownload the files\nRead in the files\n\nIntegration of samplesMerge the files\nCheck for batch\nCorrect the batch\nMarker identification\nBatch correction conclusion\n\nPseudotimeDownload provided files\nRead in provided files\nMerge the files\nCheck for batch\nRun pseudotime\n\n\nBackground\nThis script walks though the steps to correct batch effects and find pseudotemporal relationships between single cells. You can download the script which contains all of the following code and you can run yourself here https://github.com/rnabioco/cellar/tree/master/_posts/2021-10-26-class-3 and download “class-3.Rmd”\n\nshow\n# Load packages\nlibrary(Seurat)\nlibrary(cowplot)\nlibrary(knitr)\nlibrary(tidyverse)\nlibrary(LaCroixColoR)\nlibrary(viridis)\nlibrary(RColorBrewer)\nlibrary(harmony)\nlibrary(slingshot)\nlibrary(ggridges)\nlibrary(tradeSeq)\nlibrary(pheatmap)\nlibrary(here)\n\n# Set theme\nggplot2::theme_set(ggplot2::theme_classic(base_size = 10))\n\nbase_dir <- here()\n\n\n\nDescription of data\nWe will use two datasets today. The first is associated with the publication “Single-cell RNA sequencing of murine islets shows high cellular complexity at all stages of autoimmune diabetes”. In this publication, the authors were trying to characterize the immune cell response during onset of diabetes in nonobese diabetic (NOD) mice. NOD mice are an autoimmune model for Type 1 diabetes where T cells lead the destruction of insulin producing Beta cells. To characterize the development of diabetes, they performed a timecourse experiment looking at immune cells in the pancreatic islet at 4 weeks, 8 weeks, and 15 weeks of age.\n\n4 wk is about the first time that the first infiltrating T cells can be identified; 8 wk represents a time when leukocyte infiltration is prominent in most islets, still with no evidence of dysglycemia; and 15 wk is just before the time when clinical diabetes becomes evident.\n\nTo further complicate their design, samples were processed in two batches, the first batch contained one 4 week, one 8 week, and one 15 week sample. The second batch contained one 4 week and one 8 week sample.\nWe will start with just one of the 4 week samples from this dataset. The others we will include when we look at pseudotime.\nThe second dataset is from the paper “Single-cell transcriptome analysis defines heterogeneity of the murine pancreatic ductal tree”. They isolated all islet and ductal cells, so some of the cells overlap with the first dataset and some do not. We will use all cells for this analysis.\nDownload the files (Just an example, don’t run today)\nAll of the timecourse samples were downloaded here. https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE141784. This group uploaded all of the filtered csv files from cellranger for each sample. These will be downloaded if you download the GSE141784_RAW.tar file. I have alread downloaded these files for you and ran basic filtering and aligning with the provided metadata using the code below. You do not need to run anything in this section, it is just provided so you can see all of the steps to process this data.\n\nshow\n################################## DO NOT RUN ################################## \n# This function will create a seurat object, filter to the cells used in the \n# publication and add in the provided meta data.\nmake_seurat <- function(sample_list){\n  print(sample_list[[\"sample_full\"]])\n  sample_counts <- Read10X(file.path(data_dir, \"raw_data\",\n                               sample_list[\"sample_full\"]))\n\n  sample_object <- CreateSeuratObject(counts = sample_counts,\n                                      project = sample_list[\"sample_full\"],\n                                      min.cells = 5)\n\n  # Subset meta data to only the current sample\n  meta_data_short <- meta_data %>%\n    filter(Sample == sample_list[\"sample\"] & Batch == sample_list[\"batch\"])\n  \n  # Change the barcode to match each sample pre-merging\n  meta_data_short$Barcode <- sub(pattern = \"-[0-9]\", replacement = \"-1\",\n                                 meta_data_short$Barcode)\n\n  # Subset to only cells in meta data\n  sample_object <- subset(sample_object, cells = meta_data_short$Barcode)\n\n  # Check if identical\n  print(identical(meta_data_short$Barcode, colnames(sample_object)))\n\n  rownames(meta_data_short) <- meta_data_short$Barcode\n\n  sample_object <- AddMetaData(sample_object, metadata = meta_data_short)\n\n  # Add mitochondrial percent\n  sample_object[[\"percent.mt\"]] <- PercentageFeatureSet(sample_object,\n                                                    pattern = \"^mt-\")\n  \n  sample_object <- CellCycleScoring(sample_object,\n                                  s.features = s.genes,\n                                  g2m.features = g2m.genes,\n                                  set.ident = FALSE)\n  \n\n  # Normalize\n  sample_object <- NormalizeData(sample_object) %>% \n    FindVariableFeatures() %>%\n    ScaleData()\n  return(sample_object)\n}\n\n# Set directories\nbase_dir <- here()\n\ndata_dir <- file.path(base_dir, \"data\")\n\n# Read in meta data\nmeta_data <- read.table(file.path(data_dir,\n                                  \"GSE141784_Annotation_meta_data.txt\"),\n                        header = T)\n# Set sample information\nsample_list <- list(\n  c(sample_full = \"NOD_15w_2734\", sample = \"NOD_15w\", batch = 2734),\n  c(sample_full = \"NOD_4w_2734\", sample = \"NOD_4w\", batch = 2734),\n  c(sample_full = \"NOD_4w_2849\", sample = \"NOD_4w\", batch = 2849),\n  c(sample_full = \"NOD_8w_2734\", sample = \"NOD_8w\", batch = 2734),\n  c(sample_full = \"NOD_8w_2849\", sample = \"NOD_8w\", batch = 2849))\n\n# Cell cycle genes (taken from seurat cc.genes and translated to mouse genes)\ns.genes <- c(\"Exo1\", \"Mcm4\", \"Msh2\", \"Gmnn\", \"Chaf1b\", \"Mcm2\", \"Rrm2\",\n             \"Rad51ap1\", \"Gins2\", \"Hells\", \"Cdc6\", \"Ubr7\", \"Cdc45\", \"Fen1\",\n             \"Rpa2\", \"Slbp\", \"Uhrf1\", \"Ung\", \"Mcm5\", \"Dtl\", \"Casp8ap2\",\n             \"Wdr76\", \"Nasp\", \"Prim1\", \"Cdca7\", \"Clspn\", \"Pola1\", \"Mcm6\",\n             \"Blm\", \"Dscc1\", \"Usp1\", \"Tipin\", \"Rfc2\", \"Brip1\", \"Rrm1\",\n             \"Rad51\", \"Tyms\", \"Ccne2\", \"E2f8\", \"Pcna\")    \ng2m.genes <- c(\"Ctcf\", \"Smc4\", \"Dlgap5\", \"Cdc25c\", \"Gtse1\", \"Kif20b\", \"Ncapd2\",\n               \"Ttk\", \"G2e3\", \"Lbr\",  \"Cks1brt\", \"Cdca2\", \"Tacc3\", \"Anp32e\",\n               \"Cdca3\", \"Ckap2\", \"Cks2\", \"Hmgb2\", \"Top2a\", \"Tpx2\", \"Kif23\",\n               \"Rangap1\", \"Psrc1\", \"Cks1b\", \"Aurkb\", \"Hmmr\", \"Cenpf\", \"Birc5\",\n               \"Cdca8\", \"Ckap5\", \"Kif2c\", \"Kif11\", \"Hjurp\", \"Cenpe\", \"Nuf2\",\n               \"Ndc80\", \"Nek2\", \"Cdc20\", \"Ect2\", \"Anln\", \"Tubb4b\", \"Bub1\",\n               \"Aurka\", \"Ckap2l\", \"Ccnb2\", \"Nusap1\", \"Mki67\", \"Ube2c\", \"Cenpa\")\n\n# Make a list of seurat objects\nseurat_list <- lapply(sample_list, make_seurat)\n\n\n\nThe files associated with the second can be downloaded here https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM4826923. This group only uploaded their output files from 10x genomics, so I remade the object, performed the initial steps of analysis and identified celltypes by looking for clusters that shared the most marker genes with each of their identified cell types.\nDownload the files\nI have already created processed Seurat objects that we will use today. This processing included finding mitochondrial percents, creating a cell cycle score, normalizing the data, finding variable genes, and scaling the data. We will skip this today, but all steps are shown in the code segment above. We can use the code below to create a “data” directory (folder) and download the files into it.\n\nshow\n## Make a data directory only if it doesn't already exist\nifelse(!dir.exists(file.path(base_dir, \"data\")),\n       dir.create(file.path(base_dir, \"data\")), FALSE)\n\n\n[1] FALSE\n\n\nshow\n## DOWNLOAD FILES if they haven't already been downloaded\n\nifelse(!file.exists(file.path(base_dir, \"data\", \"NOD_4w_2734.rda\")),\n       download.file(\n  url = \"http://amc-sandbox.ucdenver.edu/User60/single_cell_workshop/NOD_4w_2734.rda\",\n              destfile = file.path(base_dir, \"data\", \"NOD_4w_2734.rda\")),\n  FALSE)\n\n\n[1] FALSE\nshow\nifelse(!file.exists(file.path(base_dir, \"data\", \"hendley_seurat.rda\")),\n       download.file(\n  url = \"http://amc-sandbox.ucdenver.edu/User60/single_cell_workshop/hendley_seurat.rda\",\n              destfile = file.path(base_dir, \"data\", \"hendley_seurat.rda\")),\n  FALSE)\n\n\n[1] FALSE\n\nRead in the files\n\nshow\nsample_name <- \"NOD_4w_2734\"\n\nsample_two_name <- \"hendley_seurat\"\n\nseurat_object <- readRDS(file.path(base_dir, \"data\", paste0(sample_name, \".rda\")))  \n\nseurat_two <- readRDS(file.path(base_dir, \"data\", paste0(sample_two_name, \".rda\")))\n\n\n\nIntegration of samples\nBefore we integrate samples, we first need to decide if there is a batch effect that we need to worry about. To do this, I first merge all of the samples together and use a few quick plots.\nMerge the files\nWe can take this list and pass it to the merge function from Seurat. This function takes one seurat object as x and a list of Seurat objects for y. This function automatically merges the data slots, so we won’t need to repeat normalization. We can see other options by typing ?merge\n\nshow\n# merge objects\nseurat_merge <- merge(x = seurat_object,\n                      y = seurat_two)\n\n\n\nLet’s now look at this new object\n\nshow\nprint(seurat_merge)\n\n\nAn object of class Seurat \n18788 features across 16846 samples within 1 assay \nActive assay: RNA (18788 features, 0 variable features)\n\nYou can see that we no longer have variable features, so we will need to find new variable features and rescale the data\n\nshow\n# Remeber if you want to regress out any variables, you can do that using ScaleData\nseurat_merge <- FindVariableFeatures(seurat_merge) %>%\n  ScaleData()\n\n\n\nWe also will need to repeat PCA and UMAP\n\nshow\n# It's best to set a seed before running UMAP\nset.seed(0)\nseurat_merge <- RunPCA(seurat_merge) %>%\n  FindNeighbors(dims = 1:30) %>%\n  FindClusters(resolution = 0.8) %>%\n  RunUMAP(dims = 1:30, assay = \"RNA\")\n\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 16846\nNumber of edges: 662672\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9215\nNumber of communities: 31\nElapsed time: 3 seconds\n\nCheck for batch\nNow we should check if any sort of batch correction is necessary. Let’s check by dataset. The dataset is stored as orig.ident in the object\n\nshow\nprint(head(seurat_merge[[]]))\n\n\n                      orig.ident nCount_RNA nFeature_RNA\nAAACGGGAGGAGTTTA-1_1 NOD_4w_2734        755          424\nAACCGCGAGGAGTAGA-1_1 NOD_4w_2734       1044          559\nACATACGGTCGCATCG-1_1 NOD_4w_2734        686          465\nAGGCCACTCAAGGCTT-1_1 NOD_4w_2734       2019          994\nAGTGGGAAGGGAACGG-1_1 NOD_4w_2734       1168          607\nATCATCTCAATCGGTT-1_1 NOD_4w_2734        779          393\n                                Barcode Cells Sample Batch Library\nAAACGGGAGGAGTTTA-1_1 AAACGGGAGGAGTTTA-1 Bcell NOD_4w  2734       6\nAACCGCGAGGAGTAGA-1_1 AACCGCGAGGAGTAGA-1 Bcell NOD_4w  2734       6\nACATACGGTCGCATCG-1_1 ACATACGGTCGCATCG-1 Bcell NOD_4w  2734       6\nAGGCCACTCAAGGCTT-1_1 AGGCCACTCAAGGCTT-1 Bcell NOD_4w  2734       6\nAGTGGGAAGGGAACGG-1_1 AGTGGGAAGGGAACGG-1 Bcell NOD_4w  2734       6\nATCATCTCAATCGGTT-1_1 ATCATCTCAATCGGTT-1 Bcell NOD_4w  2734       6\n                     percent.mt      S.Score    G2M.Score Phase\nAAACGGGAGGAGTTTA-1_1   2.913907 -0.009980040 -0.015109121    G1\nAACCGCGAGGAGTAGA-1_1   3.065134  0.034031936  0.030183982     S\nACATACGGTCGCATCG-1_1   3.498542  0.065019960  0.148715782   G2M\nAGGCCACTCAAGGCTT-1_1   3.268945  0.129091816  0.235910145   G2M\nAGTGGGAAGGGAACGG-1_1   3.595890  0.003709248 -0.001416123     S\nATCATCTCAATCGGTT-1_1   1.412067  0.015019960  0.013133401     S\n                     RNA_snn_res.0.8 seurat_clusters RNA_cluster\nAAACGGGAGGAGTTTA-1_1               2               2        <NA>\nAACCGCGAGGAGTAGA-1_1               9               9        <NA>\nACATACGGTCGCATCG-1_1              12              12        <NA>\nAGGCCACTCAAGGCTT-1_1              12              12        <NA>\nAGTGGGAAGGGAACGG-1_1               9               9        <NA>\nATCATCTCAATCGGTT-1_1               2               2        <NA>\n                     pANN_0.25_0.05_478\nAAACGGGAGGAGTTTA-1_1                 NA\nAACCGCGAGGAGTAGA-1_1                 NA\nACATACGGTCGCATCG-1_1                 NA\nAGGCCACTCAAGGCTT-1_1                 NA\nAGTGGGAAGGGAACGG-1_1                 NA\nATCATCTCAATCGGTT-1_1                 NA\n                     DF.classifications_0.25_0.05_478 Doublet_finder\nAAACGGGAGGAGTTTA-1_1                             <NA>           <NA>\nAACCGCGAGGAGTAGA-1_1                             <NA>           <NA>\nACATACGGTCGCATCG-1_1                             <NA>           <NA>\nAGGCCACTCAAGGCTT-1_1                             <NA>           <NA>\nAGTGGGAAGGGAACGG-1_1                             <NA>           <NA>\nATCATCTCAATCGGTT-1_1                             <NA>           <NA>\n                     RNA_snn_res.0.4\nAAACGGGAGGAGTTTA-1_1            <NA>\nAACCGCGAGGAGTAGA-1_1            <NA>\nACATACGGTCGCATCG-1_1            <NA>\nAGGCCACTCAAGGCTT-1_1            <NA>\nAGTGGGAAGGGAACGG-1_1            <NA>\nATCATCTCAATCGGTT-1_1            <NA>\n\nWe can now plot to see if these look different, which they do. In samples with bad batch effects, like these two samples, no cells will overlap. You can see that the samples almost are a mirror image of each other.\n\nshow\nbatch_colors <- LaCroixColoR::lacroix_palette(\"Pamplemousse\", 2)\nnames(batch_colors) <- unique(seurat_merge$orig.ident)\n\nDimPlot(seurat_merge, group.by = \"orig.ident\", cols = batch_colors)\n\n\n\n\nThese two datasets are interesting because they contain some, but not all, of the same celltypes\n\nshow\nprint(table(seurat_object$Cells))\n\n\n\n                       Bcell                          CD4 \n                          25                          283 \n                         CD8                          cDC \n                         148                          200 \n     Contamination_Endocrine          Contamination_Neutr \n                          31                            1 \nContamination_Red_blood_cell                           EC \n                           8                         5206 \n                         gdT                         ILC2 \n                          10                            7 \n                         Mac                  Mesenchymal \n                        1711                         1193 \n                          NK                          NKT \n                          26                           58 \n                         pDC             Undefined_Stroma \n                          84                           28 \n\n\nshow\nprint(table(seurat_two$Cells))\n\n\n\n                  Bcell                     CD4 \n                    624                     681 \n                    CD8                     cDC \n                    566                     305 \n           Ductal_cells                      EC \n                   2073                     611 \n            Fibroblasts Germinal_center_B_cells \n                     73                     232 \n                    Mac                     pDC \n                   2533                      21 \n            Plasma_cell                 unknown \n                     86                      22 \n\n\nshow\nDimPlot(seurat_merge, group.by = \"Cells\", split.by = \"orig.ident\",\n        reduction = \"umap\")\n\n\n\n\nCorrect the batch\nI personally first use harmony as my batch correction tool. There are some really nice benchmarking papers for batch correction that can give you more information on the best tool to use.\nhttps://doi.org/10.1186/s13059-019-1850-9\nhttps://doi.org/10.1101/2020.05.22.111161\nHarmony works by weakly clustering cells and then calculating - and iteratively refining - a dataset correction factor for each cluster. Note that Harmony only computes a new corrected dimensionality reduction - it does not calculate corrected expression values (the raw.data, data and scale.data slots are unmodified). This works well for most datasets, but can be be insufficient for downstream differential expression analyses in extremely divergent samples.\nActually running harmony with a seurat object is quite simple, you just use a function called RunHarmony. We can see the inputs to this function by using ?RunHarmony\nWe will use plot_convergence = TRUE so that we can ensure each iteration improves\n\nshow\n# Here we use \"orig.ident\", but we can use anything from the meta data\nseurat_merge <- RunHarmony(object = seurat_merge,\n                           group.by.vars = \"orig.ident\",\n                           plot_convergence = TRUE)\n\n\n\n\nThe objective function should be continuously improving. In this case, it’s not perfect, but probably good enough. I recomend changing the theta parameter if the function gets severely worse in later itearation.\nThe returned object now has a new dimensional reduction called harmony.\n\nshow\nprint(seurat_merge)\n\n\nAn object of class Seurat \n18788 features across 16846 samples within 1 assay \nActive assay: RNA (18788 features, 2000 variable features)\n 3 dimensional reductions calculated: pca, umap, harmony\n\nWe can use this to rerun our UMAP. I like to use a reduction key for my umap so I remember that it was made with harmony\n\nshow\nset.seed(0)\nseurat_merge <- FindNeighbors(seurat_merge,\n                              dims = 1:30, reduction = \"harmony\") %>%\n  FindClusters(resolution = 0.8) %>%\n  RunUMAP(dims = 1:30, assay = \"RNA\", reduction = \"harmony\",\n          reduction.key = \"harmony.UMAP_\", reduction.name = \"harmony.umap\")\n\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 16846\nNumber of edges: 662316\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9062\nNumber of communities: 31\nElapsed time: 2 seconds\n\nWe can check with some plots. Now we need to specify the reduction. Below we can see that in many places cells overlap and in some places they don’t. If harmony worked, the common cell types should overlap while the unique celltypes should not\n\nshow\nprint(seurat_merge)\n\n\nAn object of class Seurat \n18788 features across 16846 samples within 1 assay \nActive assay: RNA (18788 features, 2000 variable features)\n 4 dimensional reductions calculated: pca, umap, harmony, harmony.umap\n\n\nshow\nDimPlot(seurat_merge, group.by = \"orig.ident\", cols = batch_colors,\n        reduction = \"harmony.umap\")\n\n\n\n\nNow we can check celltypes\n\nshow\nDimPlot(seurat_merge, group.by = \"Cells\",\n        reduction = \"harmony.umap\")\n\n\n\n\nOverall, this looks great. The ductal cells should only be in one dataset which is true, same with the Mesenchymal cells. The other cell types mix nicely.\n\nshow\nDimPlot(seurat_merge, group.by = \"Cells\", split.by = \"orig.ident\",\n        reduction = \"harmony.umap\")\n\n\n\n\nJust to visualize more clearly, we can visualize specific celltypes in each dataset.\n\nshow\nIdents(seurat_merge) <- \"Cells\"\nplots <- lapply(c(\"Bcell\", \"CD4\", \"CD8\", \"Mac\"), function(x){\n  return(DimPlot(seurat_merge, group.by = \"Cells\", split.by = \"orig.ident\",\n                 cells.highlight = CellsByIdentities(object = seurat_merge,\n                                                     idents = x),\n                 reduction = \"harmony.umap\"))\n})\n\nplot_grid(plotlist = plots,\n          nrow = 2, ncol = 2)\n\n\n\n\nMarker identification\nWe can now identify markers based on this integrated dataset. We can identify markers of celltypes that are conserved in both datasets using the funciton FindConservedMarkers. First, we can set the identity of the cells to the celltypes. The below function takes several minutes to run, so we will skip it here. It also requires a couple of additional packages\n\nshow\n################################## DO NOT RUN ################################## \nBiocManager::install('multtest')\ninstall.packages('metap')\nIdents(seurat_merge) <- \"Cells\"\n\nmacrophage_markers <- FindConservedMarkers(seurat_merge,\n                                           ident.1 = \"Mac\",\n                                           grouping.var = \"orig.ident\")\n\nprint(macrophage_markers[1:20,])\n\n\n\nWe can also identify any differences between the macrophage populations in the two samples. This would be more interesting if one was a treatment and one was a control.\nFirst, we need to create a new column in the metadata that contains both sample information and cell type information\n\nshow\nseurat_merge$sample_celltype <- paste0(seurat_merge$orig.ident, \"_\",\n                                       seurat_merge$Cells)\n\n\n\nNow we can find markers between two populations\n\nshow\nIdents(seurat_merge) <- \"sample_celltype\"\nmac_sample_markers <- FindMarkers(seurat_merge, ident.1 = \"NOD_4w_2734_Mac\",\n                                  ident.2 = \"GSM4826923_C57BL6J_Mac\")\n\nprint(mac_sample_markers[1:20,])\n\n\n          p_val avg_log2FC pct.1 pct.2 p_val_adj\nPid1          0  -1.937315 0.137 0.810         0\nCfh           0  -2.892699 0.122 0.904         0\nRgs1          0   3.430878 0.871 0.158         0\nGas5          0   2.893606 0.805 0.000         0\nMrc1          0  -4.001585 0.037 0.968         0\nRpl35         0   1.324887 0.992 0.990         0\nZeb2          0  -1.669259 0.428 0.930         0\nGatm          0   2.738485 0.950 0.492         0\nPltp          0  -1.937587 0.188 0.785         0\nCtsz          0   1.720703 0.944 0.764         0\nRpl22l1       0   1.551200 0.937 0.794         0\nMbnl1         0  -2.005029 0.276 0.908         0\nFcrls         0  -2.771061 0.016 0.855         0\nTxnip         0  -2.085770 0.205 0.873         0\nRpsa-ps10     0   1.522140 0.469 0.000         0\nWwp1          0  -2.726688 0.032 0.840         0\nCd72          0   2.332359 0.756 0.196         0\nPrdx1         0   1.868586 0.969 0.884         0\nCcdc23        0   1.602846 0.492 0.000         0\nCela3b        0  -2.566615 0.002 0.734         0\n\nOne thing to remember while looking for differences between samples is that we had to perform a batch correction. Batch correction with harmony only corrects the dimensional reduction, not the gene counts so here we are likely also picking up on batch differences.\nTo save memory, we can remove the seurat objects from our enverionment\n\nshow\nrm(list = c(\"seurat_merge\", \"seurat_object\", \"seurat_two\"))\ngc()\n\n\n            used   (Mb) gc trigger   (Mb) limit (Mb)  max used   (Mb)\nNcells   7451162  398.0   13508872  721.5         NA  13508872  721.5\nVcells 132954762 1014.4  420601280 3209.0      65536 420600479 3209.0\n\nBatch correction conclusion\nWhile I personally prefer harmony as my batch correction, it only helps identify shared celltypes or clusters while not actually correcting the sequencing counts. This is fine if you want to find differences between shared celltypes within each sample, but it may not be correct if you want to compare expression differences between samples. There are other batch correction tools that do allow you to also correct the expression values. One that has received high marks recently is scVI, which is implemented in python so we won’t go into it here. Unfortunately, the creators of scVI don’t seem comfortable with these corrected values being used to perform differential expression analysis between samples. Seurat also performs an integration that corrects expression values, but those creators also suggest using the uncorrected RNA matrix for differential expression testing.\nAn alternative option if you have replicates is to use muscat which creates pseudobulk profiles for each cell type in each sample and then runs traditional differential expression tests that can account for variation within replicates when running differential expression.\nPseudotime\nWe can also perform puseoditme analysis on integrated samples.\nDownload provided files\nI have already created processed Seurat objects that we will use today. This processing included finding mitochondrial percents, creating a cell cycle score, normalizing the data, finding variable genes, and scaling the data. We will skip this today, but all steps are shown in the code segment above.\n\nshow\n## DOWNLOAD FILES if they haven't already been downloaded\n\nifelse(!file.exists(file.path(base_dir, \"data\", \"NOD_4w_2849.rda\")),\n       download.file(\n  url = \"http://amc-sandbox.ucdenver.edu/User60/single_cell_workshop/NOD_4w_2849.rda\",\n              destfile = file.path(base_dir, \"data\", \"NOD_4w_2849.rda\")),\n  FALSE)\n\n\n[1] FALSE\nshow\nifelse(!file.exists(file.path(base_dir, \"data\", \"NOD_8w_2734.rda\")),\n       download.file(\n  url = \"http://amc-sandbox.ucdenver.edu/User60/single_cell_workshop/NOD_8w_2734.rda\",\n              destfile = file.path(base_dir, \"data\", \"NOD_8w_2734.rda\")),\n  FALSE)\n\n\n[1] FALSE\nshow\nifelse(!file.exists(file.path(base_dir, \"data\", \"NOD_8w_2849.rda\")),\n       download.file(\n  url = \"http://amc-sandbox.ucdenver.edu/User60/single_cell_workshop/NOD_8w_2849.rda\",\n              destfile = file.path(base_dir, \"data\", \"NOD_8w_2849.rda\")),\n  FALSE)\n\n\n[1] FALSE\nshow\nifelse(!file.exists(file.path(base_dir, \"data\", \"NOD_15w_2734.rda\")),\n       download.file(\n  url = \"http://amc-sandbox.ucdenver.edu/User60/single_cell_workshop/NOD_15w_2734.rda\",\n              destfile = file.path(base_dir, \"data\", \"NOD_15w_2734.rda\")),\n  FALSE)\n\n\n[1] FALSE\nshow\nifelse(!file.exists(file.path(base_dir, \"data\", \"meta_data.rda\")),\n       download.file(\n  url = \"http://amc-sandbox.ucdenver.edu/User60/single_cell_workshop/meta_data.rda\",\n              destfile = file.path(base_dir, \"data\", \"meta_data.rda\")),\n  FALSE)\n\n\n[1] FALSE\nshow\nifelse(!file.exists(file.path(base_dir, \"data\", \"mac_sce.rda\")),\n       download.file(\n  url = \"http://amc-sandbox.ucdenver.edu/User60/single_cell_workshop/mac_sce.rda\",\n              destfile = file.path(base_dir, \"data\", \"mac_sce.rda\")),\n  FALSE)\n\n\n[1] FALSE\n\nRead in provided files\nFirst, we need to read in all of the files associated with the first dataset. Seurat wants files as a list to merge, so let’s read them in that way using lapply\n\nshow\nsample_names <- c(\"NOD_4w_2734\", \"NOD_4w_2849\",\n                  \"NOD_8w_2734\", \"NOD_8w_2849\",\n                  \"NOD_15w_2734\")\n\n# I hate the default R colors, so I will also make my own\ncolors <- RColorBrewer::brewer.pal(5, \"Set1\")\nnames(colors) <- sample_names\n\nseurat_list <- lapply(sample_names, function(x){\n  seurat_object <- readRDS(file.path(base_dir, \"data\", paste0(x, \".rda\")))  \n})\n\n\n\nMerge the files\nWe can take this list and pass it to the merge function from Seurat.\n\nshow\n# merge objects\nseurat_merge <- merge(x = seurat_list[[1]],\n                      y = seurat_list[2:length(seurat_list)])\n\n\n\nClean up memory\n\nshow\n# Remove the list\nrm(list = \"seurat_list\")\ngc()\n\n\n            used   (Mb) gc trigger   (Mb) limit (Mb)  max used   (Mb)\nNcells   7531176  402.3   13508872  721.5         NA  13508872  721.5\nVcells 301128023 2297.5  903723747 6894.9      65536 739787099 5644.2\n\nPrepare data\nOne important thing to remember about running pseudotime is that connections will be found between cells that are related or not. Because we know that the macrophages should not become B cells, we should first subset to only the macrophage population.\n\nshow\nIdents(seurat_merge) <- \"Cells\"\nseurat_mac <- subset(seurat_merge, idents = \"Mac\")\n\n\n\n\nshow\nrm(list = \"seurat_merge\")\ngc()\n\n\n            used   (Mb) gc trigger   (Mb) limit (Mb)  max used   (Mb)\nNcells   7481384  399.6   13508872  721.5         NA  13508872  721.5\nVcells 160809119 1226.9  722978998 5515.9      65536 739787099 5644.2\n\nAfter subestting, we need to repeat some of the processing steps. We need to find variable genes, scale the data, run pca, and run umap\n\nshow\nset.seed(0)\nseurat_mac <- FindVariableFeatures(seurat_mac) %>%\n  ScaleData() %>%\n  RunPCA(npcs = 30) %>%\n  FindNeighbors(dims = 1:15, reduction = \"pca\") %>%\n  FindClusters(resolution = 0.4) %>%\n  RunUMAP(dims = 1:15, assay = \"RNA\", reduction = \"pca\")\n\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 5975\nNumber of edges: 198660\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8329\nNumber of communities: 8\nElapsed time: 0 seconds\n\nCheck for batch\nNow we should check if any sort of batch correction is necessary. This data was processed in two batches. The cells within these two batches should only differ because of technical effects. To view these potential effects, we can first plot by batch.\n\nshow\nhead(seurat_mac[[]])\n\n\n                      orig.ident nCount_RNA nFeature_RNA\nTGTGGTACAATGAAAC-1_1 NOD_4w_2734       5504         2104\nTTAGGCAGTTGTTTGG-1_1 NOD_4w_2734       7174         2452\nTTAGGCATCATCACCC-1_1 NOD_4w_2734       6893         2398\nAAACGGGAGCTGAACG-1_1 NOD_4w_2734       1306          639\nAAACGGGAGGACGAAA-1_1 NOD_4w_2734       1074          523\nAAACGGGCAAGCTGAG-1_1 NOD_4w_2734       6761         2073\n                                Barcode Cells Sample Batch Library\nTGTGGTACAATGAAAC-1_1 TGTGGTACAATGAAAC-1   Mac NOD_4w  2734       6\nTTAGGCAGTTGTTTGG-1_1 TTAGGCAGTTGTTTGG-1   Mac NOD_4w  2734       6\nTTAGGCATCATCACCC-1_1 TTAGGCATCATCACCC-1   Mac NOD_4w  2734       6\nAAACGGGAGCTGAACG-1_1 AAACGGGAGCTGAACG-1   Mac NOD_4w  2734       6\nAAACGGGAGGACGAAA-1_1 AAACGGGAGGACGAAA-1   Mac NOD_4w  2734       6\nAAACGGGCAAGCTGAG-1_1 AAACGGGCAAGCTGAG-1   Mac NOD_4w  2734       6\n                     percent.mt     S.Score    G2M.Score Phase\nTGTGGTACAATGAAAC-1_1   3.143169 -0.03649368 -0.004545299    G1\nTTAGGCAGTTGTTTGG-1_1   2.815723 -0.11072854  0.019745783   G2M\nTTAGGCATCATCACCC-1_1   3.003047 -0.01443779 -0.040919110    G1\nAAACGGGAGCTGAACG-1_1   6.125574  0.08270126  0.001381862     S\nAAACGGGAGGACGAAA-1_1   3.351955 -0.01197605  0.005858639   G2M\nAAACGGGCAAGCTGAG-1_1   3.283538 -0.03344977 -0.067185912    G1\n                     RNA_snn_res.0.4 seurat_clusters\nTGTGGTACAATGAAAC-1_1               1               1\nTTAGGCAGTTGTTTGG-1_1               1               1\nTTAGGCATCATCACCC-1_1               0               0\nAAACGGGAGCTGAACG-1_1               3               3\nAAACGGGAGGACGAAA-1_1               3               3\nAAACGGGCAAGCTGAG-1_1               1               1\n\n\nshow\nDimPlot(seurat_mac, group.by = \"Batch\", cols = \"Set1\")\n\n\n\n\nWhile this isn’t as bad as our previous example, we should still try to remove the batch effect. Here we can include both the batch information as variable.\nNote we can also include the original identity in our batch correction. We can include as many correction factors as we want here, but I hesitate to correct beyond batch because I don’t want to remove our biological effect. In a real analysis, I would try removing just with batch and with batch and orig.ident\n\nshow\nseurat_mac <- RunHarmony(seurat_mac, group.by.vars = c(\"Batch\"))\n\n\n\nWe can now repeat clustering and performing UMAP dimensional reduction on this new batch corrected data.\n\nshow\nseurat_mac <- FindNeighbors(seurat_mac, dims = 1:15, reduction = \"harmony\") %>%\n  FindClusters(resolution = 0.4) %>%\n  RunUMAP(dims = 1:15, assay = \"RNA\", reduction = \"harmony\")\n\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 5975\nNumber of edges: 196762\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8356\nNumber of communities: 6\nElapsed time: 0 seconds\nshow\nDimPlot(seurat_mac, group.by = \"Batch\", cols = \"Set1\")\n\n\n\n\nThis looks much better. We can also check the sample and original identity. If we had also used orig.ident in the correction, we may be concerned that we over-corrected the timecourse. It is always good to keep what you corrected in mind as you continue your analysis.\n\nshow\nsamples <- unique(seurat_mac$Sample)\nsample_colors <- LaCroixColoR::lacroix_palette(\"Coconut\", 3)\nnames(sample_colors) <- samples\nDimPlot(seurat_mac, group.by = \"Sample\", cols = sample_colors)\n\n\n\n\n\nshow\nDimPlot(seurat_mac, group.by = \"orig.ident\", cols = \"Set1\")\n\n\n\n\n\nshow\nDimPlot(seurat_mac, group.by = \"seurat_clusters\", cols = \"Set1\")\n\n\n\n\nNote your UMAP and clusters may look slightly different than mine. That is okay. There are random seeds used to generate UMAPs and to run other functions that are influenced by that packages and versions of packages on your system. For now, we can just run it and acknowledge that all of our output may be a bit different\nRun pseudotime\nAs with batch correction, there are many tools for pseudotime. RNA velocity or velocyto are interesting methods that rely on intron retention to predict future cell state. Other options just use transcriptome similarity to identify cells that are likely related. With this second type, we cannot use the tool to identify the direction of cell development, but we can use known biology to infer this relationship. There are also good benchmarking papers that compare pseudotime methods.\nhttps://doi.org/10.1038/s41587-019-0071-9\nslingshot tends to do well in these benchmarking studies, so I generally start with that. But I find it is a good idea to compare a couple of methods to make sure your conclusions are robust.\nNow we can run slingshot. Slingshot runs on your dimensionality reduction. Some tutorials show this being run on the UMAP dimensions, but it is best to run this either on the PCA (or harmony) reduction. The UMAP is generally generated based on the PCA (or harmony) dimensional reduction and is only 2 dimensions. PCA or harmony can be many dimensions (ex. 50) and is a better representation of your data.\nFirst we need to pull the new harmony coordinates and cluster information from the seurat object. Make sure we use the same number of coordiantes we’ve used for other analysis\n\nshow\npca_coords <- Embeddings(object = seurat_mac, reduction = \"harmony\")[ , 1:15]\nclusters <- seurat_mac$seurat_clusters\n\n\n\nWe can then input these into slingshot\n\nshow\nmac_slingshot <- slingshot(data = pca_coords, clusterLabels = clusters)\n\n\n\nLooking at this object, we can see that 4 lineages were found.\n\nshow\nmac_slingshot\n\n\nclass: SlingshotDataSet \n\n Samples Dimensions\n    5975         15\n\nlineages: 3 \nLineage1: 5  1  0  2  \nLineage2: 5  1  0  3  \nLineage3: 5  1  0  4  \n\ncurves: 3 \nCurve1: Length: 43.684  Samples: 5020.65\nCurve2: Length: 62.279  Samples: 4675.3\nCurve3: Length: 78.562  Samples: 4604.8\n\nSo cluster 5, 1 and 0 start all lineages.\nPseudotime algorithims identify cells with similar transcriptional profiles to create a likely order of cell relationships. Unfortunately, there is no way to do this with a definite direction. For example, the curves above could either start or end at cluster 0, we don’t know.\nOne nice thing about slingshot is that you can include known biology to improve the ability to identify correct lineages that go in the correct direction. For example, without any input, slingshot defined cluster 0 as the first cluster, but we know that the cells at the latest timepoint are in cluster 0 while the earliest is in cluster 2. We can repeat with cluster 3 as the starting cluster\nWe can then input these into slingshot\n\nshow\nmac_slingshot_2 <- slingshot(data = pca_coords, clusterLabels = clusters,\n                             start.clus = 3)\n\n\n\nWe still find 3 lineages, but this time, all lineages start with cluster 3.\n\nshow\nprint(mac_slingshot_2)\n\n\nclass: SlingshotDataSet \n\n Samples Dimensions\n    5975         15\n\nlineages: 3 \nLineage1: 3  0  1  5  \nLineage2: 3  0  2  \nLineage3: 3  0  4  \n\ncurves: 3 \nCurve1: Length: 57.994  Samples: 4688.6\nCurve2: Length: 46.386  Samples: 3683.64\nCurve3: Length: 90.59   Samples: 3188.61\n\nWe can extract pseudotime values using slingPseudotime and add this to the metadata. This is the way that you would do it if you were running your own analysis…\n\nshow\n################################## DO NOT RUN ################################## \npseudotime <- data.frame(slingPseudotime(mac_slingshot_2))\nseurat_mac <- AddMetaData(seurat_mac, metadata = pseudotime)\n\n\n\n… but to keep our analysis consistent, you will add in my values here\n\nshow\nseurat_meta_data <- readRDS(file.path(base_dir, \"data\", \"meta_data.rda\"))\nseurat_mac <- AddMetaData(seurat_mac, metadata = seurat_meta_data)\n\n\n\nAnd now we can visualize each curve\n\nshow\nFeaturePlot(seurat_mac, features = \"curve1\", cols = viridis::magma(20))\n\n\n\n\n\nshow\nFeaturePlot(seurat_mac, features = \"curve2\", cols = viridis::magma(20))\n\n\n\n\n\nshow\nFeaturePlot(seurat_mac, features = \"curve3\", cols = viridis::magma(20))\n\n\n\n\nWe can now visualize the psuedotime across our timepoints. Below you can see that the cells nicely transition between timepoints along pseudotime.\n\nshow\nmeta_data <- seurat_mac[[]]\nmeta_data$Sample <- factor(meta_data$Sample,\n                           levels =c(\"NOD_4w\", \"NOD_8w\", \"NOD_15w\"))\n\n# Subest to only cells with value for curve 1\nmeta_data <- meta_data %>%\n  dplyr::filter(!is.na(curve1))\n\ndensity_plot <- ggplot2::ggplot(data = meta_data,\n                                ggplot2::aes(x = curve1,\n                                             y = Sample,\n                                             fill = Sample)) +\n  ggridges::geom_density_ridges() +\n  ggplot2::scale_fill_manual(values = sample_colors)\n\ndensity_plot\n\n\n\n\nAs discussed before, this could be completley due to batch effect, but we can plot each batch separetly to see if there is much difference in terms of pseudotime. As you can see, the batches look nearly identical indicating that the changes we see are likely due to the timecourse.\n\nshow\nmeta_data <- seurat_mac[[]]\nmeta_data$orig.ident <- factor(meta_data$orig.ident,\n                           levels =c(\"NOD_4w_2734\", \"NOD_4w_2849\",\n                                     \"NOD_8w_2734\", \"NOD_8w_2849\",\n                                     \"NOD_15w_2734\"))\n\n# Subest to only cells with value for curve 1\nmeta_data <- meta_data %>%\n  dplyr::filter(!is.na(curve1))\n\ndensity_plot <- ggplot2::ggplot(data = meta_data,\n                                ggplot2::aes(x = curve1,\n                                             y = orig.ident,\n                                             fill = orig.ident)) +\n  ggridges::geom_density_ridges() +\n  ggplot2::scale_fill_manual(values = colors)\n\ndensity_plot\n\n\n\n\nGenes that correlate with pseudotime\nWe can also identify genes with expression patterns that correlate with pseudotime.\nFor each gene, we will fit a general additive model (GAM) using a negative binomial noise distribution to model the (potentially nonlinear) relationship between gene expression and pseudotime. We will then test for significant associations between expression and pseudotime using the associationTest This requires the package tradeSeq\nThis function takes a long time to run (about 30 minutes) so I have already run it for you. The steps are below. I only ran it on the top 2000 variable genes as these are the most likely genes to also correlate with pseudotime.\n\nshow\n################################## DO NOT RUN ################################## \nvariable_features_pattern <- paste0(\"^\", VariableFeatures(seurat_mac), \"$\")\ngenes_use <- grep(paste0(variable_features_pattern, collapse=\"|\"),\n                  rownames(seurat_mac))\n# fit negative binomial GAM\nmac_sce <- fitGAM(counts = GetAssayData(object = seurat_mac,\n                                                slot = \"counts\"),\n                          sds = mac_slingshot_2,\n                          genes = genes_use)\n\nsaveRDS(mac_sce, file.path(base_dir, \"data\", \"mac_sce.rda\"))\n\n\n\nWe can load in this saved object and run an association test to identify what genes correlate best with pseudotime. The output of this assocaition test is a data frame that includes p values and wald statistics for each lineage.\n\nshow\nmac_sce <- readRDS(file.path(base_dir, \"data\", \"mac_sce.rda\"))\npseudotime_genes <- associationTest(mac_sce, lineages = TRUE)\nhead(pseudotime_genes)\n\n\n                waldStat df       pvalue waldStat_1 df_1     pvalue_1\n2610203C22Rik  57.393916 13 1.528750e-07 47.3931492    4 1.262831e-09\nCrispld1        1.392254 13 9.999722e-01  1.2694737    4 8.665331e-01\nMcm3          243.363823 13 0.000000e+00  3.9649927    4 4.107643e-01\nPrim2          96.215024 13 8.992806e-15  7.2718169    4 1.222024e-01\nArhgef4         5.729941 13 9.554316e-01  0.1094587    4 9.985559e-01\nKansl3         11.489114 13 5.699136e-01  2.2217701    4 6.950457e-01\n              waldStat_2 df_2  pvalue_2   waldStat_3 df_3\n2610203C22Rik 5.53169442    4 0.2369575   4.46907210    5\nCrispld1      0.04703618    4 0.9997277   0.07574365    5\nMcm3          4.95251819    4 0.2922042 234.44631244    5\nPrim2         5.11069663    4 0.2761268  83.83251057    5\nArhgef4       0.56266118    4 0.9671211   5.05782073    5\nKansl3        7.32038404    4 0.1198954   1.94695982    5\n                  pvalue_3 meanLogFC\n2610203C22Rik 4.840321e-01 0.3605775\nCrispld1      9.999183e-01 0.2334851\nMcm3          0.000000e+00 0.6827228\nPrim2         1.110223e-16 0.7987538\nArhgef4       4.088645e-01 1.3436817\nKansl3        8.564344e-01 0.2269093\n\nLet’s first pull out the top genes associated with the first curve.\n\nshow\n# We care about lineage one, so we use pvalue_1 to rank the genes.\ntopgenes <- rownames(pseudotime_genes[order(pseudotime_genes$pvalue_1), ])[1:100]\n\n\n\nWe can now plot these genes in a heatmap to show the expression over time.\n\nshow\n# Get the information for curve 1 so we can find what cells to keep\ncell_info <- seurat_mac[[\"curve1\"]]\n\ncell_info <- cell_info %>%\n  dplyr::filter(!is.na(curve1))\n\n# Get the data for all cells\nheatdata <- GetAssayData(object = seurat_mac, slot = \"data\")\n\n# Subset to only genes and cells we want\nheatdata <- heatdata[rownames(heatdata) %in% topgenes,\n                     colnames(heatdata) %in% rownames(cell_info)]\n\n# Order the data based on the pseudotime ordering of the cells\nheatdata <- heatdata[ , order(cell_info$curve1)]\n\n## Color the clusters and samples ##\n# pull out the sample information and make cell order the same as the heatmap\n# data\nsample_info <- seurat_mac[[c(\"Sample\", \"seurat_clusters\")]]\nsample_info <- sample_info[colnames(heatdata) , ]\n\n# Set colors\ncluster_colors <- RColorBrewer::brewer.pal(8, \"Set1\")\nnames(cluster_colors) <- c(0:7)\n\nsamples <- unique(seurat_mac$Sample)\nsample_colors <- LaCroixColoR::lacroix_palette(\"Coconut\", 3)\nnames(sample_colors) <- samples\n\n# We make a list of the colors, make sure the names match the sample info we\n# created\ncolor_list <- list(Sample = sample_colors, seurat_clusters = cluster_colors)\n\n## Prepare heatmap values ##\n# Scale the heatmap values\nheatmap_scale <- t(scale(t(as.matrix(heatdata)), scale = TRUE))\n\n# Colors for heatmap (from the ArchR package)\nblueYellow <- c(\"#352A86\", \"#343DAE\", \"#0262E0\", \"#1389D2\", \"#2DB7A3\",\n                \"#A5BE6A\", \"#F8BA43\", \"#F6DA23\", \"#F8FA0D\")\n\n# Add cutoffs for visualization. I actually stole this line of code from the\n# Seurat heatmap functions. Without it you can only see some genes\nheatmap_scale <- ifelse(heatmap_scale > 2.5, 2.5, heatmap_scale)\nheatmap_scale <- ifelse(heatmap_scale < -2.5, -2.5, heatmap_scale)\n\n# Make the heatmap\npheatmap(heatmap_scale, cluster_rows = TRUE,\n         cluster_cols = FALSE,\n         show_rownames = TRUE,\n         show_colnames = FALSE,\n         annotation_col = sample_info,\n         annotation_colors = color_list, color = blueYellow,\n         border_color = NA, clustering_method = \"complete\")\n\n\n\n\nWe can also visualize the expression of certain genes across pseudotime. I am going to write a function for this because we will do it several times. This is a quick function that could be easily improved to also be able to color by a continuous variable –> feel free to take this and modify as you please.\n\nshow\nplot_pseudotime <- function(seurat_object, pseudotime_name,\n                            gene_name, col_by = \"seurat_clusters\",\n                            colors = NULL){\n  plot_info <- FetchData(seurat_object, c(pseudotime_name, gene_name,\n                                          col_by))\n  \n  colnames(plot_info) <- c(\"pseudotime\", \"gene\", \"color\")\n  \n  # Set colors if not set already\n  if(is.null(colors)){\n    colors <- RColorBrewer::brewer.pal(length(unique(plot_info$color)))\n    names(colors) <- unique(plot_info$color)\n  }\n  \n  plot <- ggplot2::ggplot(plot_info, ggplot2::aes(x = pseudotime,\n                                                  y = gene,\n                                                  color = color)) +\n    ggplot2::geom_point() +\n    ggplot2::scale_color_manual(values = colors, name = col_by) + \n    ggplot2::ylab(paste0(gene_name, \" log expression\")) +\n    ggplot2::geom_smooth(se = FALSE, color = \"black\")\n  \n  return(plot)\n}\n\n\n\nLet’s run this with a few genes\n\nshow\nplot_pseudotime(seurat_mac, pseudotime_name = \"curve1\", gene_name = \"Ptma\",\n                col_by = \"seurat_clusters\", color = cluster_colors)\n\n\n\n\n\nshow\nplot_pseudotime(seurat_mac, pseudotime_name = \"curve1\", gene_name = \"Pmepa1\",\n                col_by = \"seurat_clusters\", color = cluster_colors)\n\n\n\n\n\nshow\nplot_pseudotime(seurat_mac, pseudotime_name = \"curve1\", gene_name = \"Cd72\",\n                col_by = \"seurat_clusters\", color = cluster_colors)\n\n\n\n\n\nshow\nplot_pseudotime(seurat_mac, pseudotime_name = \"curve1\", gene_name = \"Ptpn1\",\n                col_by = \"seurat_clusters\", color = cluster_colors)\n\n\n\n\n\nshow\nplot_pseudotime(seurat_mac, pseudotime_name = \"curve1\", gene_name = \"Slamf8\",\n                col_by = \"seurat_clusters\", color = cluster_colors)\n\n\n\n\nWith this function, we can also see expression by sample\n\nshow\nplot_pseudotime(seurat_mac, pseudotime_name = \"curve1\", gene_name = \"Slamf8\",\n                col_by = \"Sample\", color = sample_colors)\n\n\n\n\nBut maybe you are more interested in groups of genes that change. We can find clusters of genes that change using the tradeSeq package as well. If you could not install clusterExperiment, don’t run this secton (it’s our last section)\n\nshow\nlibrary(clusterExperiment)\ntopgenes <- rownames(pseudotime_genes[order(pseudotime_genes$pvalue_1), ])[1:250]\n\n# This clusters genes based on their expression across pseudotime\ncluster_patterns <- clusterExpressionPatterns(mac_sce, nPoints = 20,\n                                              genes = topgenes)\n\n\n36 parameter combinations, 36 use sequential method, 36 use subsampling method\nRunning Clustering on Parameter Combinations...\ndone.\nshow\n# We can pull out the labels and map genes to labels using the yhatScaled output\ncluster_labels <- primaryCluster(cluster_patterns$rsec)\n\nnames(cluster_labels) <- rownames(cluster_patterns$yhatScaled)\n\n# The -1 means the gene was not clustered\ncluster_labels <- cluster_labels[cluster_labels != -1]\n\n# Now let's make lists of genes based on the clusters\n\ncluster_genes <- lapply(unique(cluster_labels), function(x){\n  names(cluster_labels[cluster_labels == x])\n})\n\n# We can now make module scores with all of these lists\nseurat_mac <- AddModuleScore(seurat_mac, features = cluster_genes)\n\n\n\nWe now have module scores for each gene list\n\nshow\nprint(head(seurat_mac[[]]))\n\n\n                      orig.ident nCount_RNA nFeature_RNA\nTGTGGTACAATGAAAC-1_1 NOD_4w_2734       5504         2104\nTTAGGCAGTTGTTTGG-1_1 NOD_4w_2734       7174         2452\nTTAGGCATCATCACCC-1_1 NOD_4w_2734       6893         2398\nAAACGGGAGCTGAACG-1_1 NOD_4w_2734       1306          639\nAAACGGGAGGACGAAA-1_1 NOD_4w_2734       1074          523\nAAACGGGCAAGCTGAG-1_1 NOD_4w_2734       6761         2073\n                                Barcode Cells Sample Batch Library\nTGTGGTACAATGAAAC-1_1 TGTGGTACAATGAAAC-1   Mac NOD_4w  2734       6\nTTAGGCAGTTGTTTGG-1_1 TTAGGCAGTTGTTTGG-1   Mac NOD_4w  2734       6\nTTAGGCATCATCACCC-1_1 TTAGGCATCATCACCC-1   Mac NOD_4w  2734       6\nAAACGGGAGCTGAACG-1_1 AAACGGGAGCTGAACG-1   Mac NOD_4w  2734       6\nAAACGGGAGGACGAAA-1_1 AAACGGGAGGACGAAA-1   Mac NOD_4w  2734       6\nAAACGGGCAAGCTGAG-1_1 AAACGGGCAAGCTGAG-1   Mac NOD_4w  2734       6\n                     percent.mt     S.Score    G2M.Score Phase\nTGTGGTACAATGAAAC-1_1   3.143169 -0.03649368 -0.004545299    G1\nTTAGGCAGTTGTTTGG-1_1   2.815723 -0.11072854  0.019745783   G2M\nTTAGGCATCATCACCC-1_1   3.003047 -0.01443779 -0.040919110    G1\nAAACGGGAGCTGAACG-1_1   6.125574  0.08270126  0.001381862     S\nAAACGGGAGGACGAAA-1_1   3.351955 -0.01197605  0.005858639   G2M\nAAACGGGCAAGCTGAG-1_1   3.283538 -0.03344977 -0.067185912    G1\n                     RNA_snn_res.0.4 seurat_clusters   curve1\nTGTGGTACAATGAAAC-1_1               0               0 28.47263\nTTAGGCAGTTGTTTGG-1_1               0               0 27.58648\nTTAGGCATCATCACCC-1_1               1               1 37.36389\nAAACGGGAGCTGAACG-1_1               2               2       NA\nAAACGGGAGGACGAAA-1_1               2               2       NA\nAAACGGGCAAGCTGAG-1_1               0               0 26.34186\n                       curve2   curve3   curve4   Cluster1\nTGTGGTACAATGAAAC-1_1 28.49546 28.95305 5.676088 0.33377979\nTTAGGCAGTTGTTTGG-1_1 27.79235 27.71710 7.219584 0.38056921\nTTAGGCATCATCACCC-1_1       NA       NA       NA 0.28216979\nAAACGGGAGCTGAACG-1_1 43.01743       NA       NA 0.47671832\nAAACGGGAGGACGAAA-1_1 43.83676       NA       NA 0.06774771\nAAACGGGCAAGCTGAG-1_1 26.51367 26.37878 7.359532 0.56675710\n                        Cluster2    Cluster3    Cluster4   Cluster5\nTGTGGTACAATGAAAC-1_1 -0.23338713 -0.10060188 -0.23857820 0.41524500\nTTAGGCAGTTGTTTGG-1_1 -0.23831449 -0.12499315  0.22431976 0.10885173\nTTAGGCATCATCACCC-1_1  0.62293815 -0.01931329  0.04288274 0.42151581\nAAACGGGAGCTGAACG-1_1  0.16418156 -0.20755213 -0.22779036 1.29609586\nAAACGGGAGGACGAAA-1_1 -0.15662373 -0.06056986 -0.22113347 0.63430366\nAAACGGGCAAGCTGAG-1_1 -0.01334378 -0.17748735  0.19737181 0.07542681\n                        Cluster6    Cluster7    Cluster8   Cluster9\nTGTGGTACAATGAAAC-1_1  0.13847398  0.03839144  0.11999734 -0.2470514\nTTAGGCAGTTGTTTGG-1_1 -0.08947706  0.04199360 -0.20888382 -0.1627223\nTTAGGCATCATCACCC-1_1 -0.19591516  0.05584320 -0.00663408 -0.0650443\nAAACGGGAGCTGAACG-1_1 -0.46639265 -0.65554214 -0.17521994 -0.4202507\nAAACGGGAGGACGAAA-1_1 -0.38300833 -0.85337909 -0.10676373 -0.1782299\nAAACGGGCAAGCTGAG-1_1 -0.24384909  0.10882146 -0.17399804 -0.0341841\n                     Cluster10    Cluster11   Cluster12  Cluster13\nTGTGGTACAATGAAAC-1_1 0.9955797 -0.314083542 -0.48168935 -0.1045330\nTTAGGCAGTTGTTTGG-1_1 0.4621835 -0.132375413 -0.26626727  0.2829529\nTTAGGCATCATCACCC-1_1 0.4400951 -0.004010838 -0.56302972 -0.3860754\nAAACGGGAGCTGAACG-1_1 1.4501060  0.071832631  0.04211701 -0.3410378\nAAACGGGAGGACGAAA-1_1 0.6367916 -0.115808177 -0.78597350  0.5741420\nAAACGGGCAAGCTGAG-1_1 0.4356141 -0.073272605  0.03863495  0.3324352\n                       Cluster14  Cluster15\nTGTGGTACAATGAAAC-1_1 -0.32764880 0.30151699\nTTAGGCAGTTGTTTGG-1_1 -0.30099317 0.19211639\nTTAGGCATCATCACCC-1_1 -0.14009347 0.04622538\nAAACGGGAGCTGAACG-1_1  0.04676656 0.23903855\nAAACGGGAGGACGAAA-1_1  0.57718761 0.34490931\nAAACGGGCAAGCTGAG-1_1  0.47818854 0.18783371\n\nWe can plot these the same way we plotted the genes\n\nshow\nplot_pseudotime(seurat_mac, pseudotime_name = \"curve1\", gene_name = \"Cluster1\",\n                col_by = \"seurat_clusters\", color = cluster_colors)\n\n\n\n\n\nshow\nplot_pseudotime(seurat_mac, pseudotime_name = \"curve1\", gene_name = \"Cluster2\",\n                col_by = \"seurat_clusters\", color = cluster_colors)\n\n\n\n\n\nshow\nplot_pseudotime(seurat_mac, pseudotime_name = \"curve1\", gene_name = \"Cluster10\",\n                col_by = \"seurat_clusters\", color = cluster_colors)\n\n\n\n\n\nshow\nplot_pseudotime(seurat_mac, pseudotime_name = \"curve1\", gene_name = \"Cluster10\",\n                col_by = \"Sample\", color = sample_colors)\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-10-26-class-3/class-3_files/figure-html5/set-colors-batch-1.png",
    "last_modified": "2021-10-28T14:56:05-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-21-interacting-with-r-in-rstudio/",
    "title": "Interacting with R in Rstudio",
    "description": "A tutorial for navigating the Rstudio IDE, RMarkdown,\nand setting up Rstudio projects to organize each class.",
    "author": [
      {
        "name": "Kent Riemondy",
        "url": "https://github.com/kriemo"
      }
    ],
    "date": "2021-10-21",
    "categories": [],
    "contents": "\nRstudio is one of the most popular Integrated Development Environments (IDE) for working in R. It provides many useful tools to help conduct, document, and manage your analyses.\nIf you are unfamilar with Rstudio, the Rmarkdown format, or setting up projects in Rstudio, please watch a tutorial video (.mov format , .mp4) (~20 min) to help you get oriented.\n\n\n\n",
    "preview": "posts/2021-10-21-interacting-with-r-in-rstudio/rstudio.png",
    "last_modified": "2021-10-26T11:08:21-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-21-prerequisite-material/",
    "title": "Prerequisite material",
    "description": {},
    "author": [
      {
        "name": "Kent Riemondy",
        "url": "https://github.com/kriemo"
      }
    ],
    "date": "2021-10-21",
    "categories": [],
    "contents": "\nThis Rmarkdown document contains a series of exercises related to some R programming concepts that will be used in the workshop. After writing and executing your code please try to knit the Rmarkdown using the Knit button. We will review the answers to these questions in the pre-workshop class on Monday.\nPlease download the raw Rmarkdown from github to complete these exercises\nWe will be using many R packages in the course. Please load all of the following packages to ensure that you have the packages used in the course installed.\nIf you run into issues, please follow the instructions provided in the R package installation post, contact the instructors via email (rbi.fellows@cuanschutz.edu) and/or post to the slack channel for help.\n\n\nlibrary(Seurat)\nlibrary(scran)\nlibrary(SingleCellExperiment)\nlibrary(tidyverse)\nlibrary(scDblFinder)\nlibrary(ComplexHeatmap)\nlibrary(limma)\nlibrary(clustifyr)\nlibrary(slingshot)\nlibrary(tradeSeq)\nlibrary(cowplot)\nlibrary(scales)\nlibrary(gridExtra)\nlibrary(ComplexHeatmap)\nlibrary(destiny)\nlibrary(knitr)\nlibrary(LaCroixColoR)\nlibrary(viridis)\nlibrary(RColorBrewer)\nlibrary(harmony)\nlibrary(ggridges)\nlibrary(pheatmap)\nlibrary(clusterExperiment)\n\n\n\nmtcars is a built-in dataset that is always loaded when R is started. The data.frame contains information on various vehicles (run ?mtcars in the console for a description via the help tab). Please print the first 5 rows of the data.frame\n\n\n# answer here\n\n\n\nAssign the mtcars dataset to a new variable. Name the variable whatever you would like. Please print the first 5 rows of the new data.frame.\n\n\n# answer here\n\n\n\nSelect the mpg column from the mtcars data.frame and print the first 5 values of this vector of mpg values.\n\n\n# answer here\n\n\n\nWhat type is the mpg vector (logical, character, integer, numeric, factor) ?\n\n\n# answer here\n\n\n\nUsing the code below, add the new_info vector to the mtcars data.frame so that it is now the last column in your data.frame. Print the first 5 rows of the new data.frame. Assign the data.frame to a new variable if you would like but it is not necessary.\n\n\nnew_info <- 1:nrow(mtcars)\n# answer here\n\n\n\nUsing the code below, subset the example_matrix to a smaller matrix containing only rows 5 through 10 and columns 2 through 4.\n\n\nexample_matrix <- matrix(1:50, nrow = 10, ncol = 5)\n\n\n\nThe pipe operator (%>%) is a frequently used shortcut in the tidyverse. The pipe operator allows you to pipe data from one command to the next. See the documentation for some examples.\nPlease use the pipe operator to pipe the mtcars data.frame to the head() command\n\n\n# answer here\n\n\n\nAnother builtin dataset in R is called iris which contains information about various iris species. (run ?iris in the console for a description via the help tab). Please use ggplot (part of the tidyverse) to generate a boxplot comparing the Petal.Length across different species. Your plot should look similar to the plot shown below.\n\n\nknitr::include_graphics(\"example_plot.png\")\n\n\n\n\n\n\n# answer here\n\n\n\nMost computing systems have a concept of a working directory, which is the directory (e.g. /path/to/class/dir/) where the R process (or other language) is currently associated. This is important because when specifying paths to files (e.g. /path/to/class/dir/class2/class2.Rmd), the R process will interpret the path relative to the current working directory. For example if your working directory is /path/to/class/dir/class2 then you can specify class2.Rmd rather than /path/to/class/dir/class2/class2.Rmd to refer to the file.\nIn Rstudio there is a difference between the working directory of the RMarkdown and the working directory of the console. The working directory of the Rmarkdown will always be the same directory where the R markdown is placed. In contrast the working direcotry of the console will in general be the same as the Rstudio project directory where the .Rproj file is placed. If you are note working in a project, then it will default to your home directory (e.g. /Users/username/ in macOs). We recommend setting up an individual project for each analysis project, or in this class, for each class.\nTo illustrate please run the following in the R markdown (e.g. hit the green play button).\n\n\ngetwd()\n\n\n\nNext type and run the getwd() command in the console. What do you notice?\nIn general it is good practice to set the console working directory to the same directory as the Rmarkdown. This reduces confusion and makes it easier to run commands interactively.\nPlease use the setwd() function to set the working directory of the console to the same as the Rmarkdown. You’ll know this is successful because the path shown beneath the Console tab will be the same as the Rmarkdown path returned by running getwd() in the Rmarkdown.\nR packages generally have extensive documentation to explain the purpose of each function and how to execute each function. The documentation can be queried using the Help tab. Alternatively you can use the ? operator to pull up the documentation for specific functions. (e.g. ?sum). Most functions will describe the arguments for the function and provide example code at the bottom of the documentation that can be copied and run in the console (or R markdown).\nOne of the main packages that we will be using for single cell analysis is Seurat. We will use the built-in documentation to teach use how to run a command. First load the Seurat package, then examine the documentation for VlnPlot. Copy the code from one of the examples in the documentation and run in the rmarkdown chunk below.\nGoogle can also be used to find documentation online for functions (e.g. search for Seurat VlnPlot).\n\n\n# answer here\n\n\n\n\n\n\n",
    "preview": "posts/2021-10-21-prerequisite-material/example_plot.png",
    "last_modified": "2021-10-26T11:08:21-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-20-working-with-your-own-single-cell-data/",
    "title": "Working with your own single cell data",
    "description": "Guidelines for datasets to work with in the workshop, \ninformation on where to get public datasets, and \nexamples of how to load different data formats into R.",
    "author": [
      {
        "name": "Kent Riemondy",
        "url": "https://github.com/kriemo"
      }
    ],
    "date": "2021-10-20",
    "categories": [],
    "contents": "\nGuidelines for datasets\nWe ask that each workshop participant selects a dataset to analyze while taking the workshop. Each lecture will use standardized datasets, however we will set aside time for attendees to discuss analysis of their datasets with the instructors. Working through your own dataset (or a relevant published dataset) will reinforce concepts taught in class.\nIn this article we will discuss:\n- Guidelines and suggestions for the format of the dataset that you will analyze\n- Various data repositories and other sources of public datasets\n- Show examples of how to load various data formats into R for analysis with Seurat\nDataset format\nThe data that we will work with in the workshop will be count matrices. Count matrices are generally genes as rows and cells as columns, populated with read or UMI counts. These matrices are generated from pipelines such Cellranger (from 10x Genomics), or tools from academic labs such as Alevin (from the Patro lab), or Kallisto/Bustools (from the Pacther lab). These pipelines will align the raw FASTQ sequencing files, identify the barcodes associated with cell containing droplets, and output count matrices in various formats. Efficiently processing single cell datasets into count matrices generally requires more memory (RAM) and CPU power than is present on most laptops so we will not perform these steps in class. These steps are usually run on large compute clusters or on servers in the cloud. 10x Genomics offers a cloud service for running cellranger and the RBI has a pipeline for running cellranger on AWS.\nDataset size and complexity\nAs single cell datasets are continually growing in size (see article), so are the memory resources required for analyzing these datasets. A smaller dataset (e.g. ~5k cells) can be analyzed on a laptop with 8Gb of RAM without demanding too much memory. However, a dataset of ~50K cells generally maxes out the memory on a 2015 macbook pro with 16Gb of RAM.\nTo start analyzing single cell data, it is useful to learn the basics of the analysis working with 1 sample. However, 1 sample provides limited information, and is generally an insufficient dataset for learning new biology. Your dataset can therefore contain multiple samples, however this will increase the complexity of the analysis, particularly until we discuss methods for working with multiple samples in class 4.\nIdentifying public datasets\nIf you do not have a dataset in mind to analyze there are many sources.\n10x genomics 10x Genomics provides many datasets already processed through cellranger. You will need to register to gain access. The count matrix files to download, which contain only cell-associated barcodes, are called Feature / cell matrix (filtered).\nUCSC cellbrowser: This is collection of published datsets that have been already analyzed and placed into an interactive web browser. This is a nice resource as you can use to look at the data, and compare your own analysis to this data. When you select a dataset you can click the Data Download tab, and download the exprMatrix.tsv.gz file. Some datasets also provide seurat objects for download as well (e.g. human lung airway dataset). Note that the data included in the matrices is often already normalized, and not integer UMI counts. You will therefore want skip normalization in Seurat if you use these datasets.\nGene Expression Omnibus. Published single cell RNA-seq experiments should have their raw data deposited into GEO. Navigating GEO to find datasets is difficult and therefore it is better to first find a publication, then link to the publications dataset. A count matrix should be included as processed data with the submission, however not all datasets have these, and the data formats and naming conventions are not standardized. An example dataset from a mouse lung injury experiment is here, with the GSE113049_count_matrix.tsv.gz being the relevant UMI count matrix.\nBioconductor package: scRNAseq A curated selection of single cell datasets have been organized into a bioconductor pacakge called scRNAseq. These datasets are provided as SingleCellExperiment objects, which is the bioconductor data structure used for storing and working with single cell datasets. These can be easily converted to and from other data structures, such as Seurat, as shown in the load data from the wild section.\n\n\nlibrary(scRNAseq)\nlistDatasets()\n\n\nDataFrame with 60 rows and 5 columns\n                 Reference  Taxonomy               Part    Number\n               <character> <integer>        <character> <integer>\n1   @aztekin2019identifi..      8355               tail     13199\n2   @bach2017differentia..     10090      mammary gland     25806\n3           @bacher2020low      9606            T cells    104417\n4     @baron2016singlecell      9606           pancreas      8569\n5     @baron2016singlecell     10090           pancreas      1886\n...                    ...       ...                ...       ...\n56    @zeisel2018molecular     10090     nervous system    160796\n57     @zhao2020singlecell      9606 liver immune cells     68100\n58    @zhong2018singlecell      9606  prefrontal cortex      2394\n59  @zilionis2019singlec..      9606               lung    173954\n60  @zilionis2019singlec..     10090               lung     17549\n                      Call\n               <character>\n1        AztekinTailData()\n2        BachMammaryData()\n3        BacherTCellData()\n4   BaronPancreasData('h..\n5   BaronPancreasData('m..\n...                    ...\n56     ZeiselNervousData()\n57   ZhaoImmuneLiverData()\n58   ZhongPrefrontalData()\n59      ZilionisLungData()\n60  ZilionisLungData('mo..\n\ncellXgene CellXgene is a visualation tool for single cell datasets developed by the Chan-Zuckerberg Institute. They also host a variety of public datasets, some of which can be downloaded as Seurat objects.\nPlease contact the instructors if you have any difficulties finding an appropriate dataset\nLoad data from the wild into R\nCellranger output\nCellranger produces many output files. The files in the filtered_feature_bc_matrix directory contain the count matrix for cell-associated barcodes in a special sparseMatrix format (matrix market format) that can be loaded into R using a few different packages.\n\n\n# read into R as a sparseMatrix\nmat <- Seurat::Read10X()\n# create a seurat object from the sparseMatrix\nCreateSeuratObject(mat)\n\n# alternatively, read into R as a SingleCellExperiment object for use with bioconductor\nDropletUtils::read10xCounts()\n\n\n\nFrom UCSC cellbrowser\nSome datasets provide a Seurat object as an .rds file. Download this file if provided. If not, then the gene expression data will also be provided in a tsv file called exprMatrix.tsv.gz.\n\n\n# to download and load an .rds file\ndownload.file(\"https://cells.ucsc.edu/mouse-dev-neocortex/seurat.rds\", \"seurat.rds\")\nseurat_object <- readRDS(\"seurat.rds\")\nseurat_object\n\n\n\n\n\n# to download and read in a .tsv file\n#download.file(\"https://cells.ucsc.edu/mouse-dev-neocortex/exprMatrix.tsv.gz\", \"data.tsv.gz\")\n\n# slow way\nmat <- read.table(\"data.tsv.gz\")\n# faster way, requires the data.table R package\nmat <- data.table::fread(\"data.tsv.gz\", sep = \"\\t\", data.table = FALSE)\n\n# move column \"gene\" to rownames and remove \nrownames(mat) <- mat[, 1]\nmat[, 1] <- NULL\n\n# convert to sparseMatrix to load into Seurat\nmat <- as.sparse(mat)\n\nCreateSeuratObject(mat)\n\n\n\nFrom GEO\nData in GEO has no standarized format, so you will need to adapt the approach based on the files provided. Generally we try to upload data in a .tsv,.csv or a sparseMatrix format.\nTo load a .tsv/.csv file from a GEO record you can use a similar approach as used for the .tsv file from the UCSC browser.\n\n\n# to download and read in a .tsv file\n#download.file(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE113nnn/GSE113049/suppl/GSE113049_count_matrix.tsv.gz\", \"data.tsv.gz\")\n\n# faster way, requires the data.table R package\nmat <- data.table::fread(\"data.tsv.gz\", sep = \"\\t\", data.table = FALSE)\n\n# move column \"V1\" to rownames and remove \nrownames(mat) <- mat[, 1]\nmat[, 1] <- NULL\n\n# convert to sparseMatrix to load into Seurat\nmat <- as.sparse(mat)\n\nCreateSeuratObject(mat)\n\n\n\nFrom the scRNAseq datasets\n\n\nlibrary(scRNAseq)\nlibrary(Seurat)\n# select a dataset from listDatasets()\n\n# assign to object to load into the rsession\nsce <- ZhongPrefrontalData()\n\n# convert to Seurat object from SingleCellExperiment\n# sometimes this approach will error out.\n# seurat_object <- as.Seurat(sce)\n# alternatively just extract the raw UMI counts matrix\nmat <- counts(sce)\nCreateSeuratObject(mat)\n\n\nAn object of class Seurat \n24153 features across 2394 samples within 1 assay \nActive assay: RNA (24153 features, 0 variable features)\n\nFrom the Alevin pipeline\nIf the data was generated by the Alevin pipelines you can use the tximport package to load the data into R. This process can be accelerated by also installing the fishpond package. Alevin will generate a file called quants_mat.gz which is a custom binary file with the counts matrix.\n\n\n#pseudocode\nfiles <- \"path/to/alevin/quants_mat.gz\"\ntxi <- tximport(files, type = \"alevin\")\nmat <- as.sparse(txi$counts)\nCreateSeuratObect(mat)\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-26T11:08:21-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-15-running-rrstudio-with-docker/",
    "title": "Running R/Rstudio with docker",
    "description": "In this post we will discuss how to use docker\nto run R and Rstudio in a standardized environment.",
    "author": [
      {
        "name": "Kent Riemondy",
        "url": {}
      }
    ],
    "date": "2021-10-15",
    "categories": [],
    "contents": "\nWe’ve built a docker image that contains the R packages used in the workshop and made it available on dockerhub. This image can be used if you have issues installing the recommended R packages.\nWhat is docker?\nDocker is an application that allows identical software environments (called images) to be run in different operating systems (MacOS, Linux or Windows). The standardized software environment (programs, data, and configuration) takes away the headache of trying to install and maintain software. Practically using docker also enforces a reproducible analysis environment.\nIn this post we will discuss the basics of how to:\ninstall docker\nrun docker on the command-line/terminal\nrun a docker container containing R, Rstudio\nrun a docker container for this workshop that contains a variety of single cell packages\nInstall docker\nMacOS: Install Docker desktop here: https://docs.docker.com/desktop/mac/install/\nWindows: If you do not have the WSL enabled or installed, following the instructions here: https://docs.microsoft.com/en-us/windows/wsl/install\nThen download and install Docker desktop for windows: https://docs.docker.com/desktop/windows/install/\nOpen the docker application to confirm installation.\nHow to run a docker container\nA docker image refers to the standarized software environment. A docker container is the copy of the image that is downloaded and run on a specific computer.\nIf the docker application is running, then you should be able to run a docker container in the command line. Open up Terminal in macOS or PowerShell in windows.\nIf you run the following command, an image with R and Rstudio installed (rocker/tidyverse) will be downloaded from dockerhub and activated.\ndocker run --rm -e PASSWORD=rna -p 8787:8787 rocker/tidyverse\nWe’ll explain the other command arguments in a moment.\nYou’ll see some messages that will look something like this:\nUnable to find image 'rocker/tidyverse:latest' locally\nlatest: Pulling from rocker/tidyverse\n...\n...\nStatus: Downloaded newer image for rocker/verse:latest\n[s6-init] making user provided files available at /var/run/s6/etc...exited 0.\n[s6-init] ensuring user provided files have correct perms...exited 0.\n[fix-attrs.d] applying ownership & permissions fixes...\n[fix-attrs.d] done.\n[cont-init.d] executing container initialization scripts...\n[cont-init.d] userconf: executing...\nskipping /var/run/s6/container_environment/HOME\nskipping /var/run/s6/container_environment/PASSWORD\nskipping /var/run/s6/container_environment/RSTUDIO_VERSION\n[cont-init.d] userconf: exited 0.\n[cont-init.d] done.\n[services.d] starting services\n[services.d] done.\nAfter running this command an rstudio instance will be running on your computer that you can access through your web browser. Open a browser and enter http://, followed by your ip address, followed by :8787. In you are on a linux or MacOS machine you can navigate to http//localhost:8787. If you do not know the IP address you can find it in a few ways.\nIf you select the container in the docker desktop app, you can directly open the container in a browser by clicking the open in browser button.\n\n\n\nYou can obtain the IP address from the command line.\nGet list of all of your containers using docker ps\ndocker ps\nCONTAINER ID   IMAGE          COMMAND   CREATED          STATUS          PORTS                                       NAMES\nd2629b78er4f   rocker/verse   \"/init\"   14 minutes ago   Up 14 minutes   0.0.0.0:8787->8787/tcp, :::8787->8787/tcp   blissful_jepsen\nThen use docker inspect get ip address using the value found under “CONTAINER ID”\ndocker inspect d2629b78er4f\nJust get the ip-address\ndocker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' d2629b78er4f\nNavigate to http://Your.I.p.Address:8787\nYou should see a Rstudio login page\n\n\n\nLogin to rstudio with username rstudio and password rna. You should see Rstudio running in your browser.\n\n\n\nOnce you are done playing around in rstudio you can stop the container by terminating the process in your terminal:\nGo back to your terminal and run CTRL + C in macOS or linux, or Ctrl+Break in Windows\nYou’ll see a few more messages, then the command will exit back to your prompt\ns6-finish] waiting for services.\n[s6-finish] sending all processes the TERM signal.\n[s6-finish] sending all processes the KILL signal and exiting.\n$\nWhen you initiated the docker container we used the following command:\ndocker run --rm -e PASSWORD=rna -p 8787:8787 rocker/tidyverse\nThe --rm is a special flag that tells docker to delete the container after exiting. You can verify this occurred by looking at your containers in Docker Desktop or by runnning docker ps on the command line.\nThe --rm option is a good way to start working with docker. If you don’t include this a new container will be made each time you execute docker run unless you provide different flags. This can quickly take up disk space if you are not careful so we recommend that you use --rm for now. The other advantage is this approach ensures that your R environment is restored to a clean environment each time you start the container.\nThe -e PASSWORD=rna parameter specified that the password for logging into rstudio should be rna.\nThe -p 8787:8787 parameter specified that Rstudio should be served on the 8787 port.\nHow to use and create files on your local computer\nYou may have noticed that you do not have access to local files in the rstudio instance by default. This is expected behavior as the docker container exists in an isolated environment for your local computer.\nIf you want to provide rstudio access to a local directory to allow reading and writing local files do the following:\nFind the path to a directory on your computer e.g. for the desktop on macOs use ~/Desktop or for documents in windows C:\\Documents\nadd the -v parameter which has the syntax -v /path/to/local/directory:/path/in/container. Because we are using rstudio, if we put files into the container at /home/rstudio, they will be visible to rstudio.\nTry it out: Here I am making my a class directory on my desktop (on a macOS) visible to rstudio. The class directory has 1 file called hello-world.txt.\ndocker run --rm -v ~/Desktop/class:/home/rstudio -e PASSWORD=rna -p 8787:8787 rocker/tidyverse\nIn Rstudio I can now see the hello-world.txt file, and if I make a new file in R called docker-file.txt, it will now be visible on my local computer, and persist after I exit docker.\n\n\n\nSimilarly you could write a R script or Rmarkdown document, run it in rstudio, then save the script into your local files for future reuse.\n\n\n\nUsing docker for workshop\nWe have a docker image available on dockerhub that includes the packages that will be used in the class.\nrstudio-scrnaseq\nYou can use this image in the same manner as above, instead using kenter/rstudio-scrnaseq:v0.2.\nTry it out:\ndocker run --rm -e PASSWORD=rna -p 8787:8787 kenter/rstudio-scrnaseq:v0.2\nWhen you open rstudio you should be able to load Seurat and other single cell packages. We’ve also included a test-install.Rmd document that lists and loads all of the relevant installed packages, and tests basic Seurat commands.\nAdditional resources\nIf you’ve never used docker here are some useful tutorials on using docker:\nhttps://bioconductor.org/help/docker/#quickstarthttps://jsta.github.io/r-docker-tutorial/https://replikation.github.io/bioinformatics_side/docker/docker/#important-commands\n\n\n\n",
    "preview": "posts/2021-10-15-running-rrstudio-with-docker/img/open-in-browser.png",
    "last_modified": "2021-10-26T11:08:21-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-27-multi-modal/",
    "title": "Working with Multi-modal data",
    "description": "A short tutorial describing a basic CITE-seq analysis workflow.",
    "author": [
      {
        "name": "Kent Riemondy",
        "url": "https://github.com/kriemo"
      },
      {
        "name": "Ryan Sheridan",
        "url": "https://github.com/sheridar"
      }
    ],
    "date": "2021-10-13",
    "categories": [],
    "contents": "\nExperimental design\nCITE-seq enables detection of cell surface proteins AND gene expression\n\nCITE-seq reagents\nBiolegend is the main company selling CITE-seq and cell hashing antibodies (TotalSeq). Biolegend reagents are divided into three product lines:\nTotalSeq-A: 3’ gene expression, v2 and v3 chemistry\nTotalSeq-B: 3’ gene expression, v3 chemistry\nTotalSeq-C: 5’ gene expression and V(D)J\n\nCell hashing reagents\nCell hashing allows for sample multiplexing and “super-loaded” runs with >10,000 captured cells. Super-loading results in higher doublet rates (~10% for 10,000 captured cells), but these doublets can be removed by identifying cell barcodes that are associated with multiple hashtag oligos.\n\nBiolegend cell hashing reagents for human cells include a mix of two antibodies that recognize CD298 and β2 microglobulin. Mouse hashing antibodies recognize CD45 and H-2 MHC class I.\nTotalSeq-A reagents use a different PCR handle for CITE-seq and cell hashing antibodies. This means two separate libraries have to be prepared. To ensure that the correct libraries are created, it is import to tell the sequencing core which types of antibodies were included in the experiment.\nTotalSeq-C reagents use the same PCR handle for CITE-seq and cell hashing antibodies, which means that only a single library will be prepared. However, to ensure that the correct libraries are created the core should be notified of all reagents used for the experiment.\nMULTI-seq uses lipid- and cholesterol-modified oligonucleotides.\n\nCreating a Seurat object with multiple assays\nLoading counts matrices\nThe Read10X function can be used with the output directory generated by Cell Ranger. However, public datasets can be formatted in many different ways, so it is very useful to become familar with converting between formats. Our UMI count data is stored as comma-separated files, which we can load as data.frames and then convert to sparse matrices.\nOur data today will be a collection of 4 PBMC samples that have each been “hashed” with different cell-hashtags, stained with 8 different CITE-seq antibodies, then combined and captured on the 10x platform in 1 sample.\nWe have three files that we will work with:\nCITEseq_cDNA.csv.gz: UMI count gene expression data\nCITEseq_ADT.csv.gz: Antibody count data\nCITEseq_HTO.csv.gz: Hashtag count data\n\n\n# Data URL\ndata_url <- \"https://scrnaseq-workshop.s3-us-west-2.amazonaws.com\"\n\n# Function to import counts\nimport_counts <- function(file_name, file_url = data_url) {\n  mtx <- file.path(file_url, file_name) %>%\n    read_csv() %>%\n    column_to_rownames(colnames(.[, 1])) %>%\n    as.sparse()\n\n  mtx\n}\n\n# Import gene expression matrix\nrna_mtx <- import_counts(\"CITEseq_cDNA.csv.gz\")\n\n# Import CITE-seq matrix\nadt_mtx <- import_counts(\"CITEseq_ADT.csv.gz\")\n\nrownames(adt_mtx) <- str_c(\"adt-\", rownames(adt_mtx))\nadt_mtx[, 1:10]\n\n\n#> 8 x 10 sparse Matrix of class \"dgCMatrix\"\n#>                                               \n#> adt-CD14   11   2  14   1   .   1   1  . .   1\n#> adt-CD19    9   . 165 295   .   3   6  4 2   1\n#> adt-CD3     .  19  79   2   3   6   9  3 3   4\n#> adt-CD4    69 360 293   7 159 321   1  7 7   4\n#> adt-CD45    .   .   3   4   .   1   .  . 1   .\n#> adt-CD45RA 25   3 246  16   8   5  18  6 4   9\n#> adt-CD45RO  6   4 108   6   .   2   1  2 1   3\n#> adt-CD8     7   .  36   6   .   . 473 21 7 197\n\n# Import HTO matrix\nhto_mtx <- import_counts(\"CITEseq_HTO.csv.gz\")\n\nhto_mtx[, 1:10]\n\n\n#> 4 x 10 sparse Matrix of class \"dgCMatrix\"\n#>                                             \n#> HTO28 351   .   .  .   2 161   .   .   .   .\n#> HTO29   6   2   3  1   1   2   2 107   2   .\n#> HTO30   . 131 177 60   .   .   .   . 239 155\n#> HTO44   1   .   .  . 122   . 172   .   1   .\n\nCreating a Seurat object\nWhen adding multiple assays to a Seurat object, we first must identify cell barcodes that are present in all of the datasets. If one of the assays has a different number of cell barcodes Seurat will throw an error.\n\n\n# Get list of common cell barcodes\nrna_bcs <- colnames(rna_mtx)\nadt_bcs <- colnames(adt_mtx)\nhto_bcs <- colnames(hto_mtx)\n\nmerged_bcs <- rna_bcs %>%\n  intersect(adt_bcs) %>%\n  intersect(hto_bcs)\n\n# Create Seurat object\nsobj <-  CreateSeuratObject(\n  counts    = rna_mtx[, merged_bcs], \n  min.cells = 5\n)\n\n# Add CITE-seq and cell hashing data to Seurat object\nsobj[[\"ADT\"]] <- CreateAssayObject(adt_mtx[, merged_bcs])\n\nsobj[[\"HTO\"]] <- CreateAssayObject(hto_mtx[, merged_bcs])\n  \nsobj\n\n\n#> An object of class Seurat \n#> 15032 features across 4292 samples within 3 assays \n#> Active assay: RNA (15020 features, 0 variable features)\n#>  2 other assays present: ADT, HTO\n\n\nDemultiplexing hashed samples\nWe will first use the cell hashing data to assign cells to their sample of origin. This is referred to as demultiplexing as we are using the cell hashing antibody barcodes to assign each cell to a sample.\nNormalizing HTO counts\nTo account for differences in antibody binding efficiency, CITE-seq and cell hashing data can be normalized by performing a centered log-ratio transformation for each individual antibody.\nNote that the best approach for normalizing CITE-seq data has not been settled. For a more detailed discussion, and alternative approaches, see the Normalization chapter from the Orchestrating Single Cell Analysis eBook from Bioconductor.\n\n\n# Normalize HTO counts\nsobj <- sobj %>%\n  NormalizeData(\n    assay = \"HTO\",\n    normalization.method = \"CLR\"\n  )\n\n\n\nSample demultiplexing and identification of doublets\nTo demultiplex hashed samples, the HTODemux function uses the normalized HTO counts for k-medoids clustering. This results in a cluster for each HTO. A background signal is then calculated for each HTO using cells that are not present in the HTO-specific cluster. Outlier cells from this background signal are then classified as being “positive” for the HTO if they are above a cutoff quantile value (~97% of background).\nCells that are positive for multiple HTOs are classified as doublets and cells that are not positive for any HTO are classified as “negative” cells.\nThe HTODemux function automatically adds several columns to the object meta.data:\nHTO_classification: shows positive HTOs that were identified for the cell\nHTO_classification.global: singlet classification (singlet, doublet, negative)\nhash.ID: final HTO assignment including doublet and negative classifications\n\n\n# Demultiplex samples\n# By default HTODemux will look for the \"HTO\" assay\nsobj <- sobj %>%\n  HTODemux(positive.quantile = 0.97)\n\nhead(sobj@meta.data, 2)\n\n\n#>                     orig.ident nCount_RNA nFeature_RNA nCount_ADT\n#> AAACCTGAGACAAAGG SeuratProject       3054         1217        388\n#> AAACCTGAGCTACCGC SeuratProject       2411          989        337\n#>                  nFeature_ADT nCount_HTO nFeature_HTO HTO_maxID\n#> AAACCTGAGACAAAGG            5        358            3     HTO28\n#> AAACCTGAGCTACCGC            8        180            2     HTO30\n#>                  HTO_secondID HTO_margin HTO_classification\n#> AAACCTGAGACAAAGG        HTO29   3.211027              HTO28\n#> AAACCTGAGCTACCGC        HTO29   3.448779              HTO30\n#>                  HTO_classification.global hash.ID\n#> AAACCTGAGACAAAGG                   Singlet   HTO28\n#> AAACCTGAGCTACCGC                   Singlet   HTO30\n\n# Summarize cell classifications\ntable(sobj$HTO_classification.global)\n\n\n#> \n#>  Doublet Negative  Singlet \n#>      386        1     3905\n\n# Create ridge plots showing HTO signal\nsobj %>%\n  RidgePlot(\n    assay    = \"HTO\",\n    features = rownames(hto_mtx),\n    ncol     = 2\n  )\n\n\n\n\nCompare the number of cells with each hash.ID and calculate the doublet rate\n\n\n# Calculate doublet rate\nsobj@meta.data %>%\n  group_by(HTO_classification.global) %>% \n  summarize(\n    n     = n(),\n    fract = n / nrow(.)\n  )\n\n\n#> # A tibble: 3 x 3\n#>   HTO_classification.global     n    fract\n#> * <chr>                     <int>    <dbl>\n#> 1 Doublet                     386 0.0899  \n#> 2 Negative                      1 0.000233\n#> 3 Singlet                    3905 0.910\n\n# Create bar graphs comparing cell count for each sample\ndat <- sobj@meta.data %>%\n  rownames_to_column(\"cell_id\")\n\nbars_1 <- dat %>%\n  ggplot(aes(hash.ID, fill = hash.ID)) +\n  geom_bar() +\n  labs(y = \"cell count\") +\n  theme_minimal() +\n  theme(axis.title.x = element_blank())\n\nbars_2 <- dat %>%\n  ggplot(aes(\"PBMC\", fill = hash.ID)) +\n  geom_bar() +\n  labs(y = \"cell count\") +\n  theme_minimal() +\n  theme(axis.title.x = element_blank())\n\n# Combine plots\nplot_grid(\n  bars_1, bars_2,\n  align       = \"h\",\n  nrow        = 1,\n  rel_widths  = c(1, 0.6)\n)\n\n\n\n\n\nFiltering data and assessing quality\nNow that we have assigned each cell to the appropriate sample we can continue with processing the RNA data in the same manner as before.\nAssessing data quality\n\n\n# Add mitochondrial percentage to meta.data table\nsobj <- sobj %>%\n  PercentageFeatureSet(\n    assay    = \"RNA\",\n    pattern  = \"^MT-\", \n    col.name = \"percent_mito\"\n  )\n\n# Create violin plots for gene expression data\nsobj %>%\n  VlnPlot(\n    features = c(\"nCount_RNA\", \"nFeature_RNA\", \"percent_mito\"), \n    ncol     = 3,\n    pt.size  = 0\n  )\n\n\n\n\n\n\n# Aim to sequence CITE-seq libraries at 2k-5k reads/cell, cell hashing 1k-2k reads/cell\nsobj %>%\n  VlnPlot(\n    features = c(\"nCount_ADT\", \"nCount_HTO\"),\n    ncol     = 2,\n    pt.size  = 0,\n    log      = TRUE\n  )\n\n\n\n\n\n\n# Filter cells based on HTO class, number of genes, and percent mito UMIs\nfilt_so <-  sobj %>%\n  subset(\n    nFeature_RNA > 250 &                    # Remove cells with < 250 detected genes\n    nFeature_RNA < 2500 &                   # Remove cells with > 2500 detected genes (could be doublets)\n    percent_mito < 15 &                     # Remove cells with > 0.15 mito/total reads\n    HTO_classification.global == \"Singlet\"\n  )\n\nfilt_so\n\n\n#> An object of class Seurat \n#> 15032 features across 3686 samples within 3 assays \n#> Active assay: RNA (15020 features, 0 variable features)\n#>  2 other assays present: ADT, HTO\n\n# Rename cell identities with sample names\nfilt_so <- filt_so %>%\n  RenameIdents(\n    \"HTO28\" = \"PBMC-1\",\n    \"HTO29\" = \"PBMC-2\",\n    \"HTO30\" = \"PBMC-3\",\n    \"HTO44\" = \"PBMC-4\"\n  )\n\n# Add sample names to meta.data table\nfilt_so$sample <- Idents(filt_so)\n\nhead(filt_so@meta.data, 2)\n\n\n#>                     orig.ident nCount_RNA nFeature_RNA nCount_ADT\n#> AAACCTGAGACAAAGG SeuratProject       3054         1217        388\n#> AAACCTGAGCTACCGC SeuratProject       2411          989        337\n#>                  nFeature_ADT nCount_HTO nFeature_HTO HTO_maxID\n#> AAACCTGAGACAAAGG            5        358            3     HTO28\n#> AAACCTGAGCTACCGC            8        180            2     HTO30\n#>                  HTO_secondID HTO_margin HTO_classification\n#> AAACCTGAGACAAAGG        HTO29   3.211027              HTO28\n#> AAACCTGAGCTACCGC        HTO29   3.448779              HTO30\n#>                  HTO_classification.global hash.ID percent_mito\n#> AAACCTGAGACAAAGG                   Singlet   HTO28     7.105435\n#> AAACCTGAGCTACCGC                   Singlet   HTO30     9.622563\n#>                  sample\n#> AAACCTGAGACAAAGG PBMC-1\n#> AAACCTGAGCTACCGC PBMC-3\n\n\nProcess gene expression data\nTo review the basic Seurat processing workflow, see if you can complete the following steps for our gene expression data:\nLogNormalize the counts (NormalizeData)\nFind variable features (FindVariableFeatures)\nScale the data (ScaleData)\nPerform PCA (RunPCA)\nCluster the cells (FindNeighbors, FindClusters)\nRun UMAP and plot clusters (RunUMAP)\n\n\n# Write your answer here\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n\n\n\n\nClustering cells based on antibody signal\nNormalize CITE-seq counts\nBefore clustering, we first want to normalize our CITE-seq data. Like cell hashing data, CITE-seq counts can be normalized by performing a centered log-ratio transformation.\n\n\n# Normalize CITE-seq data\nfilt_so <-  filt_so %>%\n  NormalizeData(\n    assay                = \"ADT\",\n    normalization.method = \"CLR\",\n    verbose              = FALSE\n  ) %>%  \n  ScaleData(\n    assay   = \"ADT\",\n    verbose = FALSE\n  )\n\n\n\nCluster cells using antibody signal\nSince there are only a few antibodies and not many dimensions, instead of performing PCA we can just use the scaled matrix for clustering directly. In contrast to the gene expression data, we have already done feature selection and dimensionality reduction by choosing (for very practical reasons) to only stain cells with a few antibodies that discriminate cell populations. However, if you stained cells with many (>100s) antibodies, then you may want to select variable antibodies, and use PCA for clustering.\nWe will directly pass the scaled.data matrix from the ADT assay to the FindNeighbors function, which creates a Shared Nearest Neighbor (SNN) graph that is used for clustering.\n\n\n# Cluster cells\nfilt_so <- filt_so %>%\n  FindNeighbors(\n    assay      = \"ADT\",\n    reduction  = NULL,                       # we are not using a reduction\n    dims       = NULL,                       # we do not specify dims\n    features   = rownames(filt_so[[\"ADT\"]])  # specify features to use the scaled data\n  ) %>%\n  FindClusters(\n    resolution = 0.2,\n    graph.name = \"ADT_snn\"\n  )\n\n# For clarity store clusters in meta.data as 'ADT_clusters'\nfilt_so$ADT_clusters <- filt_so$ADT_snn_res.0.2\n\n\n\nRun UMAP using antibody signal\n\n\n# Run UMAP\nfilt_so <- filt_so %>%\n  RunUMAP(\n    assay          = \"ADT\",\n    graph          = \"ADT_snn\",\n    reduction.name = \"adt_umap\",\n    reduction.key  = \"ADTUMAP_\"\n  )\n\n# Plot UMAPs\nfilt_so %>%\n  DimPlot(\n    reduction = \"adt_umap\", \n    group.by  = c(\"sample\", \"ADT_clusters\"),\n    ncol      = 2\n  )\n\n\n\n\nIdentify marker proteins\n\n\n# Identify differentially expressed proteins for each cluster\nADT_markers <- filt_so %>%\n  FindAllMarkers(\n    assay    = \"ADT\",\n    only.pos = TRUE\n  )\n\nADT_markers\n\n\n#>                     p_val avg_log2FC pct.1 pct.2     p_val_adj\n#> adt-CD8      0.000000e+00  2.8218624 1.000 0.936  0.000000e+00\n#> adt-CD4      0.000000e+00  3.7010812 1.000 0.903  0.000000e+00\n#> adt-CD14    3.266554e-144  2.4423565 0.885 0.346 2.613243e-143\n#> adt-CD45    3.678499e-102  1.1732629 0.934 0.612 2.942799e-101\n#> adt-CD45RO  2.822220e-101  2.0012303 0.987 0.865 2.257776e-100\n#> adt-CD19     2.468598e-78  0.5313502 0.993 0.912  1.974879e-77\n#> adt-CD45RA   5.105446e-09  0.6653716 0.987 0.982  4.084357e-08\n#> adt-CD191    1.720165e-81  4.9623991 1.000 0.916  1.376132e-80\n#> adt-CD45RA1  8.828050e-20  0.5971657 0.992 0.982  7.062440e-19\n#> adt-CD45RO1  1.411546e-17  0.7362115 0.984 0.871  1.129237e-16\n#>             cluster       gene\n#> adt-CD8           0    adt-CD8\n#> adt-CD4           1    adt-CD4\n#> adt-CD14          3   adt-CD14\n#> adt-CD45          3   adt-CD45\n#> adt-CD45RO        3 adt-CD45RO\n#> adt-CD19          3   adt-CD19\n#> adt-CD45RA        3 adt-CD45RA\n#> adt-CD191         4   adt-CD19\n#> adt-CD45RA1       4 adt-CD45RA\n#> adt-CD45RO1       4 adt-CD45RO\n\n\nVisualizing antibody signal\nOverlay antibody signal on UMAPs\n\n\n# Set active.assay to ADT\nfilt_so@active.assay <- \"ADT\"\n\n# Overlay antibody signal on gene expression UMAP\nfeats <- c(\n  \"adt-CD4\", \"CD4\",\n  \"adt-CD8\", \"CD8A\"\n)\n\nfilt_so %>%\n  FeaturePlot(\n    reduction = \"umap\",\n    features  = feats\n  )\n\n\n\n# Overlay antibody signal on antibody UMAP\nfilt_so %>%\n  FeaturePlot(\n    reduction = \"adt_umap\",\n    features  = feats\n  )\n\n\n\n\nRidge plots\n\n\n# Create ridge plot\nfeats <- c(\n  \"adt-CD14\", \"adt-CD45\",\n  \"adt-CD19\", \"adt-CD3\",  \n  \"adt-CD4\",  \"adt-CD8\"\n)\n\nfilt_so %>%\n  RidgePlot(features = feats)\n\n\n\n\nViolin plots\n\n\n# Create violin plots\nfeats <- c(\n  \"adt-CD4\",  \"rna_CD4\",\n  \"adt-CD19\", \"rna_CD19\"\n)\n\nfilt_so %>%\n  VlnPlot(\n    features = feats,\n    ncol     = 2\n  )\n\n\n\n\n\nClassifying cells based on antibody signal\nWe can use 2D scatterplots to derive “gates” to assign cell types in the same manner as done for flow cytometry analysis. Generally the CITE-seq signal has lower dynamic range and signal-to-noise compared to flow cytometry, but the overall patterns seen with flow cytometry are also seen with CITE-seq.\nIdentify CD19+ cells\nCD19 is a marker of B-cells, whereas CD3 is a marker of T-cells. We can compare their expression to classify B-cells.\n\n\n# Plot CD3 and CD19 signal\nCD19_plot <- filt_so %>%\n  FeatureScatter(\"adt-CD3\", \"adt-CD19\")\n\nCD19_plot\n\n\n\n\n\n\n# Identify CD19+ cells using antibody signal\nCD19_cells <- filt_so %>%\n  subset(`adt-CD19` > 2.5 & `adt-CD3` < 1) %>%\n  Cells()\n\nhead(CD19_cells)\n\n\n#> [1] \"AAACCTGAGCTACCGC\" \"AAAGCAATCTGTCCGT\" \"AACACGTGTCGCTTCT\"\n#> [4] \"AACCATGGTCTGGTCG\" \"AACGTTGTCAATCACG\" \"AACTTTCCAGCCTTGG\"\n\n# Set cell identities\nlabeled_so <- filt_so %>%\n  SetIdent(value = \"Other\") %>%\n  SetIdent(value = \"CD19+\", cells = CD19_cells)\n\n# Add cell identities to meta.data\nlabeled_so$CD19_class <- Idents(labeled_so)\n\n# Label UMAP with new cell identities\nlabeled_so %>%\n  DimPlot(reduction = \"adt_umap\")\n\n\n\n\nLabel cells using CellSelector()\n\n\n# Identify CD19+ cells using antibody signal\nlabeled_so <- filt_so %>%\n  SetIdent(value = \"Other\")\n\nlabeled_so <- CellSelector(\n  plot   = CD19_plot,\n  object = labeled_so,\n  ident  = \"B cells\"\n)\n\n# Label UMAP with new cell identities\nlabeled_so %>%\n  DimPlot(reduction = \"adt_umap\")\n\n\n\nIdentify CD4+ and CD8+ cells\nIdentify CD4+ and CD8+ cells using one of the methods shown above.\n\n\n\n\n\n# Write your answer here\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n\n\n\n\nExamine CITE-seq derived cell labels on gene expression umap\n\n\nlabeled_so %>%\n  DimPlot( \n    reduction = \"umap\",\n    group.by  = \"cell_label\"\n  )\n\n\n\n\n\nCombining CITE-seq and gene expression data\nThe authors of Seurat have implemented a new algorithm for combined data from different types of assays (e.g. antibody data and RNA data), described here and presented in a vignette.\nThe basic idea is that we want to cluster and visualize the data using both the RNA and antibody data. How to do this?\nWe could literally just merge the two datasets together then run them through Seurat. This will however end up downweighting the contribution of the antibody data because there are so few antibodies(~8) compared to RNA features (~10,000)\nSeurat has implemented a “Weighted Nearest Neighbor” approach that will combine the nearest neighbor graphs from the RNA data with the antibody data. The algorithm will calculate relative weights for the RNA or the Protein data for each cell and use these new weights to constuct a shared graph. The related weights are calculated based on the relative information content of neighboring cells in each modalitly. So if the data from one modality provides more information, it is weighted higher.\n\n\n# Need to run PCA on the antibody data\nlabeled_so <- labeled_so %>%\n  RunPCA( \n    assay          = \"ADT\", \n    features       = rownames(labeled_so[[\"ADT\"]]),\n    reduction.name = \"adt_pca\"\n  )\n\nlabeled_so <- labeled_so %>%\n  FindMultiModalNeighbors(\n    reduction.list       = list(\"pca\", \"adt_pca\"),\n    dims.list            = list(1:20, 1:6),\n    modality.weight.name = \"RNA.weight\"\n  )\n\nlabeled_so <- labeled_so %>%\n  RunUMAP(\n    nn.name        = \"weighted.nn\", \n    reduction.name = \"wnn.umap\", \n    reduction.key  = \"wnnUMAP_\"\n  )\n\n\n\n\n\nrna_umap  <- DimPlot(labeled_so, reduction = \"umap\")\nadt_umap  <- DimPlot(labeled_so, reduction = \"adt_umap\")\nboth_umap <- DimPlot(labeled_so, reduction = \"wnn.umap\")\n\nplot_grid(\n  rna_umap, adt_umap, both_umap,\n  labels = c(\"RNA\", \"ADT\", \"Both\"),\n  ncol   = 3\n)\n\n\n\n\n\nViewing results with the UCSC Cell Browser\nThe UCSC Cell Browser allows you to easily explore and share single-cell data. With the Cell Browser you can:\nView t-SNE or UMAP projections\nColor cells by metadata and gene expression\nView cluster marker genes\nRename clusters and add custom annotations to selected sets of cells\nUCSC hosts a large collection of cellbrowsers for various single cell datasets.\nMerge gene expression and antibody matrices\nWe won’t be generating these browsers in the class, however below is an example of how to build a browser. The first step is to combine the gene expression and antibody data into a single matrix.\n\n\n# Combine RNA and ADT matrices\nmerged_so   <- labeled_so\nRNA_data    <- merged_so[[\"RNA\"]]@data\nADT_data    <- merged_so[[\"ADT\"]]@data\nmerged_data <- rbind(RNA_data, ADT_data)\n\n# Add merged matrix to Seurat object\nmerged_so[[\"RNA\"]]@data <- merged_data\n\n# Set active assay\nmerged_so@active.assay <- \"RNA\"\n\n\n\nCreate Cell Browser files\nTo create the files needed for the session, we can use the make_cellbrowser function from the scbp package written by Kent Riemondy. This function extracts the required data from our Seurat object and generates configuration files needed to build the session. To include both the gene expression and antibody UMAPs, we generate separate sets of files for each.\n\n\n# Create Cell Browser directories for gene expression data\ndir.create(\n  path      = \"cellbrowser\",\n  recursive = TRUE\n)\n\n# meta.data fields to include in browser\nfeats <- c(\n  \"Sample\"      = \"sample\",\n  \"clusters\"    = \"RNA_clusters\",\n  \"ADT cluster\" = \"ADT_clusters\",\n  \"Cell label\"  = \"cell_label\",\n  \n  \"RNA UMI count\"     = \"nCount_RNA\",\n  \"Gene count\"        = \"nFeature_RNA\",\n  \"Percent mito UMIs\" = \"percent_mito\",\n  \"ADT UMI count\"     = \"nCount_ADT\",\n  \"Antibody count\"    = \"nFeature_ADT\",\n  \"HTO UMI count\"     = \"nCount_HTO\",\n  \"HTO count\"         = \"nFeature_HTO\"\n)\n\n# Create Cell Browser files for gene expression data\nmerged_so %>%\n  make_cellbrowser(\n    outdir      = \"cellbrowser\",\n    column_list = feats,\n    embeddings  = \"umap\",\n    project     = \"RNA\"\n  )\n\n\n\n\n\n# Create Cell Browser files for antibody data\nmerged_so %>%\n  make_cellbrowser(\n    outdir      = \"cellbrowser\",\n    column_list = feats,\n    embeddings  = \"adt_umap\",\n    project     = \"ADT\"\n  )\n\n\n\nBuild Cell Browser session\nTo build the cell browser session, install cbBuild. This tool will build the session using the configuration files generated in the previous step.\n\nmkdir -p cellbrowser/browser\n\ncbBuild \\\n  -i cellbrowser/RNA/cellbrowser.conf \\\n  -i cellbrowser/ADT/cellbrowser.conf \\\n  -o cellbrowser/browser \\\n  -p 8888\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-28T15:08:58-06:00",
    "input_file": {}
  }
]
