[
  {
    "path": "posts/2021-10-14-r-installation/",
    "title": "R installation",
    "description": {},
    "author": [
      {
        "name": "Kent Riemondy",
        "url": "https://github.com/kriemo"
      }
    ],
    "date": "2021-10-27",
    "categories": [],
    "contents": "\nThis article will explain how to install R, Rstudio, and packages in R.If you are already familar with this material, skip to the Install packages for workshop section to see the packages that we will use in the workshop.\nDownload R\nDownload R from CRAN. Go to the cran homepage https://cran.r-project.org/. Select your operating system.\nMacOS\nSelect the newest R version, download the .pkg file, then open and install.\nWindows\nSelect the base link, then click download to download the .exe file. Open this file to install R.\nLinux\nIf you are on linux, then follow the documentation for your linux OS.\nDownload compiler tools\nMacOS\nYou may need to install the xcode command line tools if a package requires compilation. Open the Terminal from /Applications/Utilities/ (or use the search tool to search for terminal)\nType the following into Terminal:\nxcode-select --install\nPress “Install” and verify installation by typing into terminal:\ngcc --version\nWhich should print something similar to this:\n#' gcc (GCC) 4.8.5\n#' Copyright (C) 2015 Free Software Foundation, Inc.\n#' This is free software; see the source for copying conditions.  There is NO\n#' warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\nHere’s a youtube video explainer\nNext you need to install gfortran. Follow this link and go to the “INSTALL OS-SPECIFIC GFORTRAN BINARY” section. Select the download link based on your macOS version. This will supply an installer.\nWindows\nYou need to install Rtools from CRAN. Go to this link and download the exe installer for your OS: https://cran.r-project.org/bin/windows/Rtools/\nLinux\nYou probably have a compiler already?\nDownload Rstudio\nGo to the Rstudio website and download the installer for your OS.\nInstalling packages\nOnce you have R and Rstudio set up, open up rstudio, then we will install various packages.\nIn general there are 3 common places that you can get R packages from:\nCRAN, this is the official R package repository. CRAN has 16,000+ packages, including the tidyverse (ggplot2, dplyr, etc) and Seurat. Packages are installed using the install.packages() function. A successful install only needs to be done once.\nIn your console execute the following:\ninstall.packages(\"tidyverse\")\ninstall.packages(\"Seurat\")\nTest package installation once complete by loading the package(s)\nlibrary(tidyverse)\nlibrary(Seurat)\nBioconductor, which generally has bioinformatics related packages, such as clustifyr, DESeq2, ComplexHeatmap, etc.\nTo install bioconductor packages you should use the CRAN package BiocManager. BiocManager has a function called install() to install bioconductor packages. For example to install clustifyr\ninstall.packages(\"BiocManager\")\nlibrary(BiocManager)\ninstall(\"clustifyr\")\n# or equivalently you could run BiocManager::install(\"clustifyr\")\nGithub hosts open-source code from millions of projects. R packages hosted on github can be installed using the remotes package. Presto or djvdj are examples of single cell RNA-seq analysis packages on github. You’ll need to find the organization name and the repository name on github to install.\ninstall.packages(\"remotes\")\nremotes::install_github('rnabioco/djvdj')\nremotes::install_github('immunogenomics/presto')\nInstall packages for workshop\nWe will use the following packages:\nFrom CRAN:\n- tidyverse\n- Seurat\n- rmarkdown\n- cowplot\n- pheatmap\n- markdown\n\n\ninstall.packages(c('tidyverse',\n                   'rmarkdown',\n                   'Seurat',\n                   'cowplot',\n                   'pheatmap',\n                   'markdown'))\n\n\n\nFrom Bioconductor:\n- ComplexHeatmap\n- scran\n- scDblFinder\n- limma\n- clustifyr\n- slingshot\n- tradeSeq\n- clusterExperiment\n\n\nBiocManager::install(c('ComplexHeatmap', \n                       'scran',\n                       'scDblFinder',\n                       'limma',\n                       'clustifyr',\n                       'slingshot',\n                       'tradeSeq',\n                       'clusterExperiment'))\n\n\n\nFrom github:\n- destiny (hosted on bioconductor typically but not building correctly right now) - harmony (batch correction approach) - LaCroixColoR (pretty color palette)\n\n\nremotes::install_github('theislab/destiny')\nremotes::install_github('immunogenomics/harmony')\nremotes::install_github('johannesbjork/LaCroixColoR')\n\n\n\nTo test the installation, run the prerequisite Rmarkdown which will load all of these packages.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-27T19:26:47-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-21-interacting-with-r-in-rstudio/",
    "title": "Interacting with R in Rstudio",
    "description": "A tutorial for navigating the Rstudio IDE, RMarkdown,\nand setting up Rstudio projects to organize each class.",
    "author": [
      {
        "name": "Kent Riemondy",
        "url": "https://github.com/kriemo"
      }
    ],
    "date": "2021-10-21",
    "categories": [],
    "contents": "\nRstudio is one of the most popular Integrated Development Environments (IDE) for working in R. It provides many useful tools to help conduct, document, and manage your analyses.\nIf you are unfamilar with Rstudio, the Rmarkdown format, or setting up projects in Rstudio, please watch a tutorial video (.mov format , .mp4) (~20 min) to help you get oriented.\n\n\n\n",
    "preview": "posts/2021-10-21-interacting-with-r-in-rstudio/rstudio.png",
    "last_modified": "2021-10-27T19:26:47-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-21-prerequisite-material/",
    "title": "Prerequisite material",
    "description": {},
    "author": [
      {
        "name": "Kent Riemondy",
        "url": "https://github.com/kriemo"
      }
    ],
    "date": "2021-10-21",
    "categories": [],
    "contents": "\nThis Rmarkdown document contains a series of exercises related to some R programming concepts that will be used in the workshop. After writing and executing your code please try to knit the Rmarkdown using the Knit button. We will review the answers to these questions in the pre-workshop class on Monday.\nPlease download the raw Rmarkdown from github to complete these exercises\nWe will be using many R packages in the course. Please load all of the following packages to ensure that you have the packages used in the course installed.\nIf you run into issues, please follow the instructions provided in the R package installation post, contact the instructors via email (rbi.fellows@cuanschutz.edu) and/or post to the slack channel for help.\n\n\nlibrary(Seurat)\nlibrary(scran)\nlibrary(SingleCellExperiment)\nlibrary(tidyverse)\nlibrary(scDblFinder)\nlibrary(ComplexHeatmap)\nlibrary(limma)\nlibrary(clustifyr)\nlibrary(slingshot)\nlibrary(tradeSeq)\nlibrary(cowplot)\nlibrary(scales)\nlibrary(gridExtra)\nlibrary(ComplexHeatmap)\nlibrary(destiny)\nlibrary(knitr)\nlibrary(LaCroixColoR)\nlibrary(viridis)\nlibrary(RColorBrewer)\nlibrary(harmony)\nlibrary(ggridges)\nlibrary(pheatmap)\nlibrary(clusterExperiment)\n\n\n\nmtcars is a built-in dataset that is always loaded when R is started. The data.frame contains information on various vehicles (run ?mtcars in the console for a description via the help tab). Please print the first 5 rows of the data.frame\n\n\n# answer here\n\n\n\nAssign the mtcars dataset to a new variable. Name the variable whatever you would like. Please print the first 5 rows of the new data.frame.\n\n\n# answer here\n\n\n\nSelect the mpg column from the mtcars data.frame and print the first 5 values of this vector of mpg values.\n\n\n# answer here\n\n\n\nWhat type is the mpg vector (logical, character, integer, numeric, factor) ?\n\n\n# answer here\n\n\n\nUsing the code below, add the new_info vector to the mtcars data.frame so that it is now the last column in your data.frame. Print the first 5 rows of the new data.frame. Assign the data.frame to a new variable if you would like but it is not necessary.\n\n\nnew_info <- 1:nrow(mtcars)\n# answer here\n\n\n\nUsing the code below, subset the example_matrix to a smaller matrix containing only rows 5 through 10 and columns 2 through 4.\n\n\nexample_matrix <- matrix(1:50, nrow = 10, ncol = 5)\n\n\n\nThe pipe operator (%>%) is a frequently used shortcut in the tidyverse. The pipe operator allows you to pipe data from one command to the next. See the documentation for some examples.\nPlease use the pipe operator to pipe the mtcars data.frame to the head() command\n\n\n# answer here\n\n\n\nAnother builtin dataset in R is called iris which contains information about various iris species. (run ?iris in the console for a description via the help tab). Please use ggplot (part of the tidyverse) to generate a boxplot comparing the Petal.Length across different species. Your plot should look similar to the plot shown below.\n\n\nknitr::include_graphics(\"example_plot.png\")\n\n\n\n\n\n\n# answer here\n\n\n\nMost computing systems have a concept of a working directory, which is the directory (e.g. /path/to/class/dir/) where the R process (or other language) is currently associated. This is important because when specifying paths to files (e.g. /path/to/class/dir/class2/class2.Rmd), the R process will interpret the path relative to the current working directory. For example if your working directory is /path/to/class/dir/class2 then you can specify class2.Rmd rather than /path/to/class/dir/class2/class2.Rmd to refer to the file.\nIn Rstudio there is a difference between the working directory of the RMarkdown and the working directory of the console. The working directory of the Rmarkdown will always be the same directory where the R markdown is placed. In contrast the working direcotry of the console will in general be the same as the Rstudio project directory where the .Rproj file is placed. If you are note working in a project, then it will default to your home directory (e.g. /Users/username/ in macOs). We recommend setting up an individual project for each analysis project, or in this class, for each class.\nTo illustrate please run the following in the R markdown (e.g. hit the green play button).\n\n\ngetwd()\n\n\n\nNext type and run the getwd() command in the console. What do you notice?\nIn general it is good practice to set the console working directory to the same directory as the Rmarkdown. This reduces confusion and makes it easier to run commands interactively.\nPlease use the setwd() function to set the working directory of the console to the same as the Rmarkdown. You’ll know this is successful because the path shown beneath the Console tab will be the same as the Rmarkdown path returned by running getwd() in the Rmarkdown.\nR packages generally have extensive documentation to explain the purpose of each function and how to execute each function. The documentation can be queried using the Help tab. Alternatively you can use the ? operator to pull up the documentation for specific functions. (e.g. ?sum). Most functions will describe the arguments for the function and provide example code at the bottom of the documentation that can be copied and run in the console (or R markdown).\nOne of the main packages that we will be using for single cell analysis is Seurat. We will use the built-in documentation to teach use how to run a command. First load the Seurat package, then examine the documentation for VlnPlot. Copy the code from one of the examples in the documentation and run in the rmarkdown chunk below.\nGoogle can also be used to find documentation online for functions (e.g. search for Seurat VlnPlot).\n\n\n# answer here\n\n\n\n\n\n\n",
    "preview": "posts/2021-10-21-prerequisite-material/example_plot.png",
    "last_modified": "2021-10-27T19:26:47-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-20-working-with-your-own-single-cell-data/",
    "title": "Working with your own single cell data",
    "description": "Guidelines for datasets to work with in the workshop, \ninformation on where to get public datasets, and \nexamples of how to load different data formats into R.",
    "author": [
      {
        "name": "Kent Riemondy",
        "url": "https://github.com/kriemo"
      }
    ],
    "date": "2021-10-20",
    "categories": [],
    "contents": "\nGuidelines for datasets\nWe ask that each workshop participant selects a dataset to analyze while taking the workshop. Each lecture will use standardized datasets, however we will set aside time for attendees to discuss analysis of their datasets with the instructors. Working through your own dataset (or a relevant published dataset) will reinforce concepts taught in class.\nIn this article we will discuss:\n- Guidelines and suggestions for the format of the dataset that you will analyze\n- Various data repositories and other sources of public datasets\n- Show examples of how to load various data formats into R for analysis with Seurat\nDataset format\nThe data that we will work with in the workshop will be count matrices. Count matrices are generally genes as rows and cells as columns, populated with read or UMI counts. These matrices are generated from pipelines such Cellranger (from 10x Genomics), or tools from academic labs such as Alevin (from the Patro lab), or Kallisto/Bustools (from the Pacther lab). These pipelines will align the raw FASTQ sequencing files, identify the barcodes associated with cell containing droplets, and output count matrices in various formats. Efficiently processing single cell datasets into count matrices generally requires more memory (RAM) and CPU power than is present on most laptops so we will not perform these steps in class. These steps are usually run on large compute clusters or on servers in the cloud. 10x Genomics offers a cloud service for running cellranger and the RBI has a pipeline for running cellranger on AWS.\nDataset size and complexity\nAs single cell datasets are continually growing in size (see article), so are the memory resources required for analyzing these datasets. A smaller dataset (e.g. ~5k cells) can be analyzed on a laptop with 8Gb of RAM without demanding too much memory. However, a dataset of ~50K cells generally maxes out the memory on a 2015 macbook pro with 16Gb of RAM.\nTo start analyzing single cell data, it is useful to learn the basics of the analysis working with 1 sample. However, 1 sample provides limited information, and is generally an insufficient dataset for learning new biology. Your dataset can therefore contain multiple samples, however this will increase the complexity of the analysis, particularly until we discuss methods for working with multiple samples in class 4.\nIdentifying public datasets\nIf you do not have a dataset in mind to analyze there are many sources.\n10x genomics 10x Genomics provides many datasets already processed through cellranger. You will need to register to gain access. The count matrix files to download, which contain only cell-associated barcodes, are called Feature / cell matrix (filtered).\nUCSC cellbrowser: This is collection of published datsets that have been already analyzed and placed into an interactive web browser. This is a nice resource as you can use to look at the data, and compare your own analysis to this data. When you select a dataset you can click the Data Download tab, and download the exprMatrix.tsv.gz file. Some datasets also provide seurat objects for download as well (e.g. human lung airway dataset). Note that the data included in the matrices is often already normalized, and not integer UMI counts. You will therefore want skip normalization in Seurat if you use these datasets.\nGene Expression Omnibus. Published single cell RNA-seq experiments should have their raw data deposited into GEO. Navigating GEO to find datasets is difficult and therefore it is better to first find a publication, then link to the publications dataset. A count matrix should be included as processed data with the submission, however not all datasets have these, and the data formats and naming conventions are not standardized. An example dataset from a mouse lung injury experiment is here, with the GSE113049_count_matrix.tsv.gz being the relevant UMI count matrix.\nBioconductor package: scRNAseq A curated selection of single cell datasets have been organized into a bioconductor pacakge called scRNAseq. These datasets are provided as SingleCellExperiment objects, which is the bioconductor data structure used for storing and working with single cell datasets. These can be easily converted to and from other data structures, such as Seurat, as shown in the load data from the wild section.\n\n\nlibrary(scRNAseq)\nlistDatasets()\n\n\nDataFrame with 60 rows and 5 columns\n                 Reference  Taxonomy               Part    Number\n               <character> <integer>        <character> <integer>\n1   @aztekin2019identifi..      8355               tail     13199\n2   @bach2017differentia..     10090      mammary gland     25806\n3           @bacher2020low      9606            T cells    104417\n4     @baron2016singlecell      9606           pancreas      8569\n5     @baron2016singlecell     10090           pancreas      1886\n...                    ...       ...                ...       ...\n56    @zeisel2018molecular     10090     nervous system    160796\n57     @zhao2020singlecell      9606 liver immune cells     68100\n58    @zhong2018singlecell      9606  prefrontal cortex      2394\n59  @zilionis2019singlec..      9606               lung    173954\n60  @zilionis2019singlec..     10090               lung     17549\n                      Call\n               <character>\n1        AztekinTailData()\n2        BachMammaryData()\n3        BacherTCellData()\n4   BaronPancreasData('h..\n5   BaronPancreasData('m..\n...                    ...\n56     ZeiselNervousData()\n57   ZhaoImmuneLiverData()\n58   ZhongPrefrontalData()\n59      ZilionisLungData()\n60  ZilionisLungData('mo..\n\ncellXgene CellXgene is a visualation tool for single cell datasets developed by the Chan-Zuckerberg Institute. They also host a variety of public datasets, some of which can be downloaded as Seurat objects.\nPlease contact the instructors if you have any difficulties finding an appropriate dataset\nLoad data from the wild into R\nCellranger output\nCellranger produces many output files. The files in the filtered_feature_bc_matrix directory contain the count matrix for cell-associated barcodes in a special sparseMatrix format (matrix market format) that can be loaded into R using a few different packages.\n\n\n# read into R as a sparseMatrix\nmat <- Seurat::Read10X()\n# create a seurat object from the sparseMatrix\nCreateSeuratObject(mat)\n\n# alternatively, read into R as a SingleCellExperiment object for use with bioconductor\nDropletUtils::read10xCounts()\n\n\n\nFrom UCSC cellbrowser\nSome datasets provide a Seurat object as an .rds file. Download this file if provided. If not, then the gene expression data will also be provided in a tsv file called exprMatrix.tsv.gz.\n\n\n# to download and load an .rds file\ndownload.file(\"https://cells.ucsc.edu/mouse-dev-neocortex/seurat.rds\", \"seurat.rds\")\nseurat_object <- readRDS(\"seurat.rds\")\nseurat_object\n\n\n\n\n\n# to download and read in a .tsv file\n#download.file(\"https://cells.ucsc.edu/mouse-dev-neocortex/exprMatrix.tsv.gz\", \"data.tsv.gz\")\n\n# slow way\nmat <- read.table(\"data.tsv.gz\")\n# faster way, requires the data.table R package\nmat <- data.table::fread(\"data.tsv.gz\", sep = \"\\t\", data.table = FALSE)\n\n# move column \"gene\" to rownames and remove \nrownames(mat) <- mat[, 1]\nmat[, 1] <- NULL\n\n# convert to sparseMatrix to load into Seurat\nmat <- as.sparse(mat)\n\nCreateSeuratObject(mat)\n\n\n\nFrom GEO\nData in GEO has no standarized format, so you will need to adapt the approach based on the files provided. Generally we try to upload data in a .tsv,.csv or a sparseMatrix format.\nTo load a .tsv/.csv file from a GEO record you can use a similar approach as used for the .tsv file from the UCSC browser.\n\n\n# to download and read in a .tsv file\n#download.file(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE113nnn/GSE113049/suppl/GSE113049_count_matrix.tsv.gz\", \"data.tsv.gz\")\n\n# faster way, requires the data.table R package\nmat <- data.table::fread(\"data.tsv.gz\", sep = \"\\t\", data.table = FALSE)\n\n# move column \"V1\" to rownames and remove \nrownames(mat) <- mat[, 1]\nmat[, 1] <- NULL\n\n# convert to sparseMatrix to load into Seurat\nmat <- as.sparse(mat)\n\nCreateSeuratObject(mat)\n\n\n\nFrom the scRNAseq datasets\n\n\nlibrary(scRNAseq)\nlibrary(Seurat)\n# select a dataset from listDatasets()\n\n# assign to object to load into the rsession\nsce <- ZhongPrefrontalData()\n\n# convert to Seurat object from SingleCellExperiment\n# sometimes this approach will error out.\n# seurat_object <- as.Seurat(sce)\n# alternatively just extract the raw UMI counts matrix\nmat <- counts(sce)\nCreateSeuratObject(mat)\n\n\nAn object of class Seurat \n24153 features across 2394 samples within 1 assay \nActive assay: RNA (24153 features, 0 variable features)\n\nFrom the Alevin pipeline\nIf the data was generated by the Alevin pipelines you can use the tximport package to load the data into R. This process can be accelerated by also installing the fishpond package. Alevin will generate a file called quants_mat.gz which is a custom binary file with the counts matrix.\n\n\n#pseudocode\nfiles <- \"path/to/alevin/quants_mat.gz\"\ntxi <- tximport(files, type = \"alevin\")\nmat <- as.sparse(txi$counts)\nCreateSeuratObect(mat)\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-27T19:26:47-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-15-running-rrstudio-with-docker/",
    "title": "Running R/Rstudio with docker",
    "description": "In this post we will discuss how to use docker\nto run R and Rstudio in a standardized environment.",
    "author": [
      {
        "name": "Kent Riemondy",
        "url": {}
      }
    ],
    "date": "2021-10-15",
    "categories": [],
    "contents": "\nWe’ve built a docker image that contains the R packages used in the workshop and made it available on dockerhub. This image can be used if you have issues installing the recommended R packages.\nWhat is docker?\nDocker is an application that allows identical software environments (called images) to be run in different operating systems (MacOS, Linux or Windows). The standardized software environment (programs, data, and configuration) takes away the headache of trying to install and maintain software. Practically using docker also enforces a reproducible analysis environment.\nIn this post we will discuss the basics of how to:\ninstall docker\nrun docker on the command-line/terminal\nrun a docker container containing R, Rstudio\nrun a docker container for this workshop that contains a variety of single cell packages\nInstall docker\nMacOS: Install Docker desktop here: https://docs.docker.com/desktop/mac/install/\nWindows: If you do not have the WSL enabled or installed, following the instructions here: https://docs.microsoft.com/en-us/windows/wsl/install\nThen download and install Docker desktop for windows: https://docs.docker.com/desktop/windows/install/\nOpen the docker application to confirm installation.\nHow to run a docker container\nA docker image refers to the standarized software environment. A docker container is the copy of the image that is downloaded and run on a specific computer.\nIf the docker application is running, then you should be able to run a docker container in the command line. Open up Terminal in macOS or PowerShell in windows.\nIf you run the following command, an image with R and Rstudio installed (rocker/tidyverse) will be downloaded from dockerhub and activated.\ndocker run --rm -e PASSWORD=rna -p 8787:8787 rocker/tidyverse\nWe’ll explain the other command arguments in a moment.\nYou’ll see some messages that will look something like this:\nUnable to find image 'rocker/tidyverse:latest' locally\nlatest: Pulling from rocker/tidyverse\n...\n...\nStatus: Downloaded newer image for rocker/verse:latest\n[s6-init] making user provided files available at /var/run/s6/etc...exited 0.\n[s6-init] ensuring user provided files have correct perms...exited 0.\n[fix-attrs.d] applying ownership & permissions fixes...\n[fix-attrs.d] done.\n[cont-init.d] executing container initialization scripts...\n[cont-init.d] userconf: executing...\nskipping /var/run/s6/container_environment/HOME\nskipping /var/run/s6/container_environment/PASSWORD\nskipping /var/run/s6/container_environment/RSTUDIO_VERSION\n[cont-init.d] userconf: exited 0.\n[cont-init.d] done.\n[services.d] starting services\n[services.d] done.\nAfter running this command an rstudio instance will be running on your computer that you can access through your web browser. Open a browser and enter http://, followed by your ip address, followed by :8787. In you are on a linux or MacOS machine you can navigate to http//localhost:8787. If you do not know the IP address you can find it in a few ways.\nIf you select the container in the docker desktop app, you can directly open the container in a browser by clicking the open in browser button.\n\n\n\nYou can obtain the IP address from the command line.\nGet list of all of your containers using docker ps\ndocker ps\nCONTAINER ID   IMAGE          COMMAND   CREATED          STATUS          PORTS                                       NAMES\nd2629b78er4f   rocker/verse   \"/init\"   14 minutes ago   Up 14 minutes   0.0.0.0:8787->8787/tcp, :::8787->8787/tcp   blissful_jepsen\nThen use docker inspect get ip address using the value found under “CONTAINER ID”\ndocker inspect d2629b78er4f\nJust get the ip-address\ndocker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' d2629b78er4f\nNavigate to http://Your.I.p.Address:8787\nYou should see a Rstudio login page\n\n\n\nLogin to rstudio with username rstudio and password rna. You should see Rstudio running in your browser.\n\n\n\nOnce you are done playing around in rstudio you can stop the container by terminating the process in your terminal:\nGo back to your terminal and run CTRL + C in macOS or linux, or Ctrl+Break in Windows\nYou’ll see a few more messages, then the command will exit back to your prompt\ns6-finish] waiting for services.\n[s6-finish] sending all processes the TERM signal.\n[s6-finish] sending all processes the KILL signal and exiting.\n$\nWhen you initiated the docker container we used the following command:\ndocker run --rm -e PASSWORD=rna -p 8787:8787 rocker/tidyverse\nThe --rm is a special flag that tells docker to delete the container after exiting. You can verify this occurred by looking at your containers in Docker Desktop or by runnning docker ps on the command line.\nThe --rm option is a good way to start working with docker. If you don’t include this a new container will be made each time you execute docker run unless you provide different flags. This can quickly take up disk space if you are not careful so we recommend that you use --rm for now. The other advantage is this approach ensures that your R environment is restored to a clean environment each time you start the container.\nThe -e PASSWORD=rna parameter specified that the password for logging into rstudio should be rna.\nThe -p 8787:8787 parameter specified that Rstudio should be served on the 8787 port.\nHow to use and create files on your local computer\nYou may have noticed that you do not have access to local files in the rstudio instance by default. This is expected behavior as the docker container exists in an isolated environment for your local computer.\nIf you want to provide rstudio access to a local directory to allow reading and writing local files do the following:\nFind the path to a directory on your computer e.g. for the desktop on macOs use ~/Desktop or for documents in windows C:\\Documents\nadd the -v parameter which has the syntax -v /path/to/local/directory:/path/in/container. Because we are using rstudio, if we put files into the container at /home/rstudio, they will be visible to rstudio.\nTry it out: Here I am making my a class directory on my desktop (on a macOS) visible to rstudio. The class directory has 1 file called hello-world.txt.\ndocker run --rm -v ~/Desktop/class:/home/rstudio -e PASSWORD=rna -p 8787:8787 rocker/tidyverse\nIn Rstudio I can now see the hello-world.txt file, and if I make a new file in R called docker-file.txt, it will now be visible on my local computer, and persist after I exit docker.\n\n\n\nSimilarly you could write a R script or Rmarkdown document, run it in rstudio, then save the script into your local files for future reuse.\n\n\n\nUsing docker for workshop\nWe have a docker image available on dockerhub that includes the packages that will be used in the class.\nrstudio-scrnaseq\nYou can use this image in the same manner as above, instead using kenter/rstudio-scrnaseq:v0.2.\nTry it out:\ndocker run --rm -e PASSWORD=rna -p 8787:8787 kenter/rstudio-scrnaseq:v0.2\nWhen you open rstudio you should be able to load Seurat and other single cell packages. We’ve also included a test-install.Rmd document that lists and loads all of the relevant installed packages, and tests basic Seurat commands.\nAdditional resources\nIf you’ve never used docker here are some useful tutorials on using docker:\nhttps://bioconductor.org/help/docker/#quickstarthttps://jsta.github.io/r-docker-tutorial/https://replikation.github.io/bioinformatics_side/docker/docker/#important-commands\n\n\n\n",
    "preview": "posts/2021-10-15-running-rrstudio-with-docker/img/open-in-browser.png",
    "last_modified": "2021-10-27T19:26:47-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-27-multi-modal/",
    "title": "Working with Multi-modal data",
    "description": "A short tutorial describing a basic CITE-seq analysis workflow.",
    "author": [
      {
        "name": "Kent Riemondy",
        "url": "https://github.com/kriemo"
      },
      {
        "name": "Ryan Sheridan",
        "url": "https://github.com/sheridar"
      }
    ],
    "date": "2021-10-13",
    "categories": [],
    "contents": "\nExperimental design\nCITE-seq enables detection of cell surface proteins AND gene expression\n\nCITE-seq reagents\nBiolegend is the main company selling CITE-seq and cell hashing antibodies (TotalSeq). Biolegend reagents are divided into three product lines:\nTotalSeq-A: 3’ gene expression, v2 and v3 chemistry\nTotalSeq-B: 3’ gene expression, v3 chemistry\nTotalSeq-C: 5’ gene expression and V(D)J\n\nCell hashing reagents\nCell hashing allows for sample multiplexing and “super-loaded” runs with >10,000 captured cells. Super-loading results in higher doublet rates (~10% for 10,000 captured cells), but these doublets can be removed by identifying cell barcodes that are associated with multiple hashtag oligos.\n\nBiolegend cell hashing reagents for human cells include a mix of two antibodies that recognize CD298 and β2 microglobulin. Mouse hashing antibodies recognize CD45 and H-2 MHC class I.\nTotalSeq-A reagents use a different PCR handle for CITE-seq and cell hashing antibodies. This means two separate libraries have to be prepared. To ensure that the correct libraries are created, it is import to tell the sequencing core which types of antibodies were included in the experiment.\nTotalSeq-C reagents use the same PCR handle for CITE-seq and cell hashing antibodies, which means that only a single library will be prepared. However, to ensure that the correct libraries are created the core should be notified of all reagents used for the experiment.\nMULTI-seq uses lipid- and cholesterol-modified oligonucleotides.\n\nCreating a Seurat object with multiple assays\nLoading counts matrices\nThe Read10X function can be used with the output directory generated by Cell Ranger. However, public datasets can be formatted in many different ways, so it is very useful to become familar with converting between formats. Our UMI count data is stored as comma-separated files, which we can load as data.frames and then convert to sparse matrices.\nOur data today will be a collection of 4 PBMC samples that have each been “hashed” with different cell-hashtags, stained with 8 different CITE-seq antibodies, then combined and captured on the 10x platform in 1 sample.\nWe have three files that we will work with:\nCITEseq_cDNA.csv.gz: UMI count gene expression data\nCITEseq_ADT.csv.gz: Antibody count data\nCITEseq_HTO.csv.gz: Hashtag count data\n\n\n# Data URL\ndata_url <- \"https://scrnaseq-workshop.s3-us-west-2.amazonaws.com\"\n\n# Function to import counts\nimport_counts <- function(file_name, file_url = data_url) {\n  mtx <- file.path(file_url, file_name) %>%\n    read_csv() %>%\n    column_to_rownames(colnames(.[, 1])) %>%\n    as.sparse()\n\n  mtx\n}\n\n# Import gene expression matrix\nrna_mtx <- import_counts(\"CITEseq_cDNA.csv.gz\")\n\n# Import CITE-seq matrix\nadt_mtx <- import_counts(\"CITEseq_ADT.csv.gz\")\n\nrownames(adt_mtx) <- str_c(\"adt-\", rownames(adt_mtx))\nadt_mtx[, 1:10]\n\n\n#> 8 x 10 sparse Matrix of class \"dgCMatrix\"\n#>                                               \n#> adt-CD14   11   2  14   1   .   1   1  . .   1\n#> adt-CD19    9   . 165 295   .   3   6  4 2   1\n#> adt-CD3     .  19  79   2   3   6   9  3 3   4\n#> adt-CD4    69 360 293   7 159 321   1  7 7   4\n#> adt-CD45    .   .   3   4   .   1   .  . 1   .\n#> adt-CD45RA 25   3 246  16   8   5  18  6 4   9\n#> adt-CD45RO  6   4 108   6   .   2   1  2 1   3\n#> adt-CD8     7   .  36   6   .   . 473 21 7 197\n\n# Import HTO matrix\nhto_mtx <- import_counts(\"CITEseq_HTO.csv.gz\")\n\nhto_mtx[, 1:10]\n\n\n#> 4 x 10 sparse Matrix of class \"dgCMatrix\"\n#>                                             \n#> HTO28 351   .   .  .   2 161   .   .   .   .\n#> HTO29   6   2   3  1   1   2   2 107   2   .\n#> HTO30   . 131 177 60   .   .   .   . 239 155\n#> HTO44   1   .   .  . 122   . 172   .   1   .\n\nCreating a Seurat object\nWhen adding multiple assays to a Seurat object, we first must identify cell barcodes that are present in all of the datasets. If one of the assays has a different number of cell barcodes Seurat will throw an error.\n\n\n# Get list of common cell barcodes\nrna_bcs <- colnames(rna_mtx)\nadt_bcs <- colnames(adt_mtx)\nhto_bcs <- colnames(hto_mtx)\n\nmerged_bcs <- rna_bcs %>%\n  intersect(adt_bcs) %>%\n  intersect(hto_bcs)\n\n# Create Seurat object\nsobj <-  CreateSeuratObject(\n  counts    = rna_mtx[, merged_bcs], \n  min.cells = 5\n)\n\n# Add CITE-seq and cell hashing data to Seurat object\nsobj[[\"ADT\"]] <- CreateAssayObject(adt_mtx[, merged_bcs])\n\nsobj[[\"HTO\"]] <- CreateAssayObject(hto_mtx[, merged_bcs])\n  \nsobj\n\n\n#> An object of class Seurat \n#> 15032 features across 4292 samples within 3 assays \n#> Active assay: RNA (15020 features, 0 variable features)\n#>  2 other assays present: ADT, HTO\n\n\nDemultiplexing hashed samples\nWe will first use the cell hashing data to assign cells to their sample of origin. This is referred to as demultiplexing as we are using the cell hashing antibody barcodes to assign each cell to a sample.\nNormalizing HTO counts\nTo account for differences in antibody binding efficiency, CITE-seq and cell hashing data can be normalized by performing a centered log-ratio transformation for each individual antibody.\nNote that the best approach for normalizing CITE-seq data has not been settled. For a more detailed discussion, and alternative approaches, see the Normalization chapter from the Orchestrating Single Cell Analysis eBook from Bioconductor.\n\n\n# Normalize HTO counts\nsobj <- sobj %>%\n  NormalizeData(\n    assay = \"HTO\",\n    normalization.method = \"CLR\"\n  )\n\n\n\nSample demultiplexing and identification of doublets\nTo demultiplex hashed samples, the HTODemux function uses the normalized HTO counts for k-medoids clustering. This results in a cluster for each HTO. A background signal is then calculated for each HTO using cells that are not present in the HTO-specific cluster. Outlier cells from this background signal are then classified as being “positive” for the HTO if they are above a cutoff quantile value (~97% of background).\nCells that are positive for multiple HTOs are classified as doublets and cells that are not positive for any HTO are classified as “negative” cells.\nThe HTODemux function automatically adds several columns to the object meta.data:\nHTO_classification: shows positive HTOs that were identified for the cell\nHTO_classification.global: singlet classification (singlet, doublet, negative)\nhash.ID: final HTO assignment including doublet and negative classifications\n\n\n# Demultiplex samples\n# By default HTODemux will look for the \"HTO\" assay\nsobj <- sobj %>%\n  HTODemux(positive.quantile = 0.97)\n\nhead(sobj@meta.data, 2)\n\n\n#>                     orig.ident nCount_RNA nFeature_RNA nCount_ADT\n#> AAACCTGAGACAAAGG SeuratProject       3054         1217        388\n#> AAACCTGAGCTACCGC SeuratProject       2411          989        337\n#>                  nFeature_ADT nCount_HTO nFeature_HTO HTO_maxID\n#> AAACCTGAGACAAAGG            5        358            3     HTO28\n#> AAACCTGAGCTACCGC            8        180            2     HTO30\n#>                  HTO_secondID HTO_margin HTO_classification\n#> AAACCTGAGACAAAGG        HTO29   3.211027              HTO28\n#> AAACCTGAGCTACCGC        HTO29   3.448779              HTO30\n#>                  HTO_classification.global hash.ID\n#> AAACCTGAGACAAAGG                   Singlet   HTO28\n#> AAACCTGAGCTACCGC                   Singlet   HTO30\n\n# Summarize cell classifications\ntable(sobj$HTO_classification.global)\n\n\n#> \n#>  Doublet Negative  Singlet \n#>      386        1     3905\n\n# Create ridge plots showing HTO signal\nsobj %>%\n  RidgePlot(\n    assay    = \"HTO\",\n    features = rownames(hto_mtx),\n    ncol     = 2\n  )\n\n\n\n\nCompare the number of cells with each hash.ID and calculate the doublet rate\n\n\n# Calculate doublet rate\nsobj@meta.data %>%\n  group_by(HTO_classification.global) %>% \n  summarize(\n    n     = n(),\n    fract = n / nrow(.)\n  )\n\n\n#> # A tibble: 3 x 3\n#>   HTO_classification.global     n    fract\n#> * <chr>                     <int>    <dbl>\n#> 1 Doublet                     386 0.0899  \n#> 2 Negative                      1 0.000233\n#> 3 Singlet                    3905 0.910\n\n# Create bar graphs comparing cell count for each sample\ndat <- sobj@meta.data %>%\n  rownames_to_column(\"cell_id\")\n\nbars_1 <- dat %>%\n  ggplot(aes(hash.ID, fill = hash.ID)) +\n  geom_bar() +\n  labs(y = \"cell count\") +\n  theme_minimal() +\n  theme(axis.title.x = element_blank())\n\nbars_2 <- dat %>%\n  ggplot(aes(\"PBMC\", fill = hash.ID)) +\n  geom_bar() +\n  labs(y = \"cell count\") +\n  theme_minimal() +\n  theme(axis.title.x = element_blank())\n\n# Combine plots\nplot_grid(\n  bars_1, bars_2,\n  align       = \"h\",\n  nrow        = 1,\n  rel_widths  = c(1, 0.6)\n)\n\n\n\n\n\nFiltering data and assessing quality\nNow that we have assigned each cell to the appropriate sample we can continue with processing the RNA data in the same manner as before.\nAssessing data quality\n\n\n# Add mitochondrial percentage to meta.data table\nsobj <- sobj %>%\n  PercentageFeatureSet(\n    assay    = \"RNA\",\n    pattern  = \"^MT-\", \n    col.name = \"percent_mito\"\n  )\n\n# Create violin plots for gene expression data\nsobj %>%\n  VlnPlot(\n    features = c(\"nCount_RNA\", \"nFeature_RNA\", \"percent_mito\"), \n    ncol     = 3,\n    pt.size  = 0\n  )\n\n\n\n\n\n\n# Aim to sequence CITE-seq libraries at 2k-5k reads/cell, cell hashing 1k-2k reads/cell\nsobj %>%\n  VlnPlot(\n    features = c(\"nCount_ADT\", \"nCount_HTO\"),\n    ncol     = 2,\n    pt.size  = 0,\n    log      = TRUE\n  )\n\n\n\n\n\n\n# Filter cells based on HTO class, number of genes, and percent mito UMIs\nfilt_so <-  sobj %>%\n  subset(\n    nFeature_RNA > 250 &                    # Remove cells with < 250 detected genes\n    nFeature_RNA < 2500 &                   # Remove cells with > 2500 detected genes (could be doublets)\n    percent_mito < 15 &                     # Remove cells with > 0.15 mito/total reads\n    HTO_classification.global == \"Singlet\"\n  )\n\nfilt_so\n\n\n#> An object of class Seurat \n#> 15032 features across 3686 samples within 3 assays \n#> Active assay: RNA (15020 features, 0 variable features)\n#>  2 other assays present: ADT, HTO\n\n# Rename cell identities with sample names\nfilt_so <- filt_so %>%\n  RenameIdents(\n    \"HTO28\" = \"PBMC-1\",\n    \"HTO29\" = \"PBMC-2\",\n    \"HTO30\" = \"PBMC-3\",\n    \"HTO44\" = \"PBMC-4\"\n  )\n\n# Add sample names to meta.data table\nfilt_so$sample <- Idents(filt_so)\n\nhead(filt_so@meta.data, 2)\n\n\n#>                     orig.ident nCount_RNA nFeature_RNA nCount_ADT\n#> AAACCTGAGACAAAGG SeuratProject       3054         1217        388\n#> AAACCTGAGCTACCGC SeuratProject       2411          989        337\n#>                  nFeature_ADT nCount_HTO nFeature_HTO HTO_maxID\n#> AAACCTGAGACAAAGG            5        358            3     HTO28\n#> AAACCTGAGCTACCGC            8        180            2     HTO30\n#>                  HTO_secondID HTO_margin HTO_classification\n#> AAACCTGAGACAAAGG        HTO29   3.211027              HTO28\n#> AAACCTGAGCTACCGC        HTO29   3.448779              HTO30\n#>                  HTO_classification.global hash.ID percent_mito\n#> AAACCTGAGACAAAGG                   Singlet   HTO28     7.105435\n#> AAACCTGAGCTACCGC                   Singlet   HTO30     9.622563\n#>                  sample\n#> AAACCTGAGACAAAGG PBMC-1\n#> AAACCTGAGCTACCGC PBMC-3\n\n\nProcess gene expression data\nTo review the basic Seurat processing workflow, see if you can complete the following steps for our gene expression data:\nLogNormalize the counts (NormalizeData)\nFind variable features (FindVariableFeatures)\nScale the data (ScaleData)\nPerform PCA (RunPCA)\nCluster the cells (FindNeighbors, FindClusters)\nRun UMAP and plot clusters (RunUMAP)\n\n\n# Write your answer here\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n\n\n\n\nClustering cells based on antibody signal\nNormalize CITE-seq counts\nBefore clustering, we first want to normalize our CITE-seq data. Like cell hashing data, CITE-seq counts can be normalized by performing a centered log-ratio transformation.\n\n\n# Normalize CITE-seq data\nfilt_so <-  filt_so %>%\n  NormalizeData(\n    assay                = \"ADT\",\n    normalization.method = \"CLR\",\n    verbose              = FALSE\n  ) %>%  \n  ScaleData(\n    assay   = \"ADT\",\n    verbose = FALSE\n  )\n\n\n\nCluster cells using antibody signal\nSince there are only a few antibodies and not many dimensions, instead of performing PCA we can just use the scaled matrix for clustering directly. In contrast to the gene expression data, we have already done feature selection and dimensionality reduction by choosing (for very practical reasons) to only stain cells with a few antibodies that discriminate cell populations. However, if you stained cells with many (>100s) antibodies, then you may want to select variable antibodies, and use PCA for clustering.\nWe will directly pass the scaled.data matrix from the ADT assay to the FindNeighbors function, which creates a Shared Nearest Neighbor (SNN) graph that is used for clustering.\n\n\n# Cluster cells\nfilt_so <- filt_so %>%\n  FindNeighbors(\n    assay      = \"ADT\",\n    reduction  = NULL,                       # we are not using a reduction\n    dims       = NULL,                       # we do not specify dims\n    features   = rownames(filt_so[[\"ADT\"]])  # specify features to use the scaled data\n  ) %>%\n  FindClusters(\n    resolution = 0.2,\n    graph.name = \"ADT_snn\"\n  )\n\n# For clarity store clusters in meta.data as 'ADT_clusters'\nfilt_so$ADT_clusters <- filt_so$ADT_snn_res.0.2\n\n\n\nRun UMAP using antibody signal\n\n\n# Run UMAP\nfilt_so <- filt_so %>%\n  RunUMAP(\n    assay          = \"ADT\",\n    graph          = \"ADT_snn\",\n    reduction.name = \"adt_umap\",\n    reduction.key  = \"ADTUMAP_\"\n  )\n\n# Plot UMAPs\nfilt_so %>%\n  DimPlot(\n    reduction = \"adt_umap\", \n    group.by  = c(\"sample\", \"ADT_clusters\"),\n    ncol      = 2\n  )\n\n\n\n\nIdentify marker proteins\n\n\n# Identify differentially expressed proteins for each cluster\nADT_markers <- filt_so %>%\n  FindAllMarkers(\n    assay    = \"ADT\",\n    only.pos = TRUE\n  )\n\nADT_markers\n\n\n#>                     p_val avg_log2FC pct.1 pct.2     p_val_adj\n#> adt-CD8      0.000000e+00  2.8218624 1.000 0.936  0.000000e+00\n#> adt-CD4      0.000000e+00  3.7010812 1.000 0.903  0.000000e+00\n#> adt-CD14    3.266554e-144  2.4423565 0.885 0.346 2.613243e-143\n#> adt-CD45    3.678499e-102  1.1732629 0.934 0.612 2.942799e-101\n#> adt-CD45RO  2.822220e-101  2.0012303 0.987 0.865 2.257776e-100\n#> adt-CD19     2.468598e-78  0.5313502 0.993 0.912  1.974879e-77\n#> adt-CD45RA   5.105446e-09  0.6653716 0.987 0.982  4.084357e-08\n#> adt-CD191    1.720165e-81  4.9623991 1.000 0.916  1.376132e-80\n#> adt-CD45RA1  8.828050e-20  0.5971657 0.992 0.982  7.062440e-19\n#> adt-CD45RO1  1.411546e-17  0.7362115 0.984 0.871  1.129237e-16\n#>             cluster       gene\n#> adt-CD8           0    adt-CD8\n#> adt-CD4           1    adt-CD4\n#> adt-CD14          3   adt-CD14\n#> adt-CD45          3   adt-CD45\n#> adt-CD45RO        3 adt-CD45RO\n#> adt-CD19          3   adt-CD19\n#> adt-CD45RA        3 adt-CD45RA\n#> adt-CD191         4   adt-CD19\n#> adt-CD45RA1       4 adt-CD45RA\n#> adt-CD45RO1       4 adt-CD45RO\n\n\nVisualizing antibody signal\nOverlay antibody signal on UMAPs\n\n\n# Set active.assay to ADT\nfilt_so@active.assay <- \"ADT\"\n\n# Overlay antibody signal on gene expression UMAP\nfeats <- c(\n  \"adt-CD4\", \"CD4\",\n  \"adt-CD8\", \"CD8A\"\n)\n\nfilt_so %>%\n  FeaturePlot(\n    reduction = \"umap\",\n    features  = feats\n  )\n\n\n\n# Overlay antibody signal on antibody UMAP\nfilt_so %>%\n  FeaturePlot(\n    reduction = \"adt_umap\",\n    features  = feats\n  )\n\n\n\n\nRidge plots\n\n\n# Create ridge plot\nfeats <- c(\n  \"adt-CD14\", \"adt-CD45\",\n  \"adt-CD19\", \"adt-CD3\",  \n  \"adt-CD4\",  \"adt-CD8\"\n)\n\nfilt_so %>%\n  RidgePlot(features = feats)\n\n\n\n\nViolin plots\n\n\n# Create violin plots\nfeats <- c(\n  \"adt-CD4\",  \"rna_CD4\",\n  \"adt-CD19\", \"rna_CD19\"\n)\n\nfilt_so %>%\n  VlnPlot(\n    features = feats,\n    ncol     = 2\n  )\n\n\n\n\n\nClassifying cells based on antibody signal\nWe can use 2D scatterplots to derive “gates” to assign cell types in the same manner as done for flow cytometry analysis. Generally the CITE-seq signal has lower dynamic range and signal-to-noise compared to flow cytometry, but the overall patterns seen with flow cytometry are also seen with CITE-seq.\nIdentify CD19+ cells\nCD19 is a marker of B-cells, whereas CD3 is a marker of T-cells. We can compare their expression to classify B-cells.\n\n\n# Plot CD3 and CD19 signal\nCD19_plot <- filt_so %>%\n  FeatureScatter(\"adt-CD3\", \"adt-CD19\")\n\nCD19_plot\n\n\n\n\n\n\n# Identify CD19+ cells using antibody signal\nCD19_cells <- filt_so %>%\n  subset(`adt-CD19` > 2.5 & `adt-CD3` < 1) %>%\n  Cells()\n\nhead(CD19_cells)\n\n\n#> [1] \"AAACCTGAGCTACCGC\" \"AAAGCAATCTGTCCGT\" \"AACACGTGTCGCTTCT\"\n#> [4] \"AACCATGGTCTGGTCG\" \"AACGTTGTCAATCACG\" \"AACTTTCCAGCCTTGG\"\n\n# Set cell identities\nlabeled_so <- filt_so %>%\n  SetIdent(value = \"Other\") %>%\n  SetIdent(value = \"CD19+\", cells = CD19_cells)\n\n# Add cell identities to meta.data\nlabeled_so$CD19_class <- Idents(labeled_so)\n\n# Label UMAP with new cell identities\nlabeled_so %>%\n  DimPlot(reduction = \"adt_umap\")\n\n\n\n\nLabel cells using CellSelector()\n\n\n# Identify CD19+ cells using antibody signal\nlabeled_so <- filt_so %>%\n  SetIdent(value = \"Other\")\n\nlabeled_so <- CellSelector(\n  plot   = CD19_plot,\n  object = labeled_so,\n  ident  = \"B cells\"\n)\n\n# Label UMAP with new cell identities\nlabeled_so %>%\n  DimPlot(reduction = \"adt_umap\")\n\n\n\nIdentify CD4+ and CD8+ cells\nIdentify CD4+ and CD8+ cells using one of the methods shown above.\n\n\n\n\n\n# Write your answer here\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n\n\n\n\nExamine CITE-seq derived cell labels on gene expression umap\n\n\nlabeled_so %>%\n  DimPlot( \n    reduction = \"umap\",\n    group.by  = \"cell_label\"\n  )\n\n\n\n\n\nCombining CITE-seq and gene expression data\nThe authors of Seurat have implemented a new algorithm for combined data from different types of assays (e.g. antibody data and RNA data), described here and presented in a vignette.\nThe basic idea is that we want to cluster and visualize the data using both the RNA and antibody data. How to do this?\nWe could literally just merge the two datasets together then run them through Seurat. This will however end up downweighting the contribution of the antibody data because there are so few antibodies(~8) compared to RNA features (~10,000)\nSeurat has implemented a “Weighted Nearest Neighbor” approach that will combine the nearest neighbor graphs from the RNA data with the antibody data. The algorithm will calculate relative weights for the RNA or the Protein data for each cell and use these new weights to constuct a shared graph. The related weights are calculated based on the relative information content of neighboring cells in each modalitly. So if the data from one modality provides more information, it is weighted higher.\n\n\n# Need to run PCA on the antibody data\nlabeled_so <- labeled_so %>%\n  RunPCA( \n    assay          = \"ADT\", \n    features       = rownames(labeled_so[[\"ADT\"]]),\n    reduction.name = \"adt_pca\"\n  )\n\nlabeled_so <- labeled_so %>%\n  FindMultiModalNeighbors(\n    reduction.list       = list(\"pca\", \"adt_pca\"),\n    dims.list            = list(1:20, 1:6),\n    modality.weight.name = \"RNA.weight\"\n  )\n\nlabeled_so <- labeled_so %>%\n  RunUMAP(\n    nn.name        = \"weighted.nn\", \n    reduction.name = \"wnn.umap\", \n    reduction.key  = \"wnnUMAP_\"\n  )\n\n\n\n\n\nrna_umap  <- DimPlot(labeled_so, reduction = \"umap\")\nadt_umap  <- DimPlot(labeled_so, reduction = \"adt_umap\")\nboth_umap <- DimPlot(labeled_so, reduction = \"wnn.umap\")\n\nplot_grid(\n  rna_umap, adt_umap, both_umap,\n  labels = c(\"RNA\", \"ADT\", \"Both\"),\n  ncol   = 3\n)\n\n\n\n\n\nViewing results with the UCSC Cell Browser\nThe UCSC Cell Browser allows you to easily explore and share single-cell data. With the Cell Browser you can:\nView t-SNE or UMAP projections\nColor cells by metadata and gene expression\nView cluster marker genes\nRename clusters and add custom annotations to selected sets of cells\nUCSC hosts a large collection of cellbrowsers for various single cell datasets.\nMerge gene expression and antibody matrices\nWe won’t be generating these browsers in the class, however below is an example of how to build a browser. The first step is to combine the gene expression and antibody data into a single matrix.\n\n\n# Combine RNA and ADT matrices\nmerged_so   <- labeled_so\nRNA_data    <- merged_so[[\"RNA\"]]@data\nADT_data    <- merged_so[[\"ADT\"]]@data\nmerged_data <- rbind(RNA_data, ADT_data)\n\n# Add merged matrix to Seurat object\nmerged_so[[\"RNA\"]]@data <- merged_data\n\n# Set active assay\nmerged_so@active.assay <- \"RNA\"\n\n\n\nCreate Cell Browser files\nTo create the files needed for the session, we can use the make_cellbrowser function from the scbp package written by Kent Riemondy. This function extracts the required data from our Seurat object and generates configuration files needed to build the session. To include both the gene expression and antibody UMAPs, we generate separate sets of files for each.\n\n\n# Create Cell Browser directories for gene expression data\ndir.create(\n  path      = \"cellbrowser\",\n  recursive = TRUE\n)\n\n# meta.data fields to include in browser\nfeats <- c(\n  \"Sample\"      = \"sample\",\n  \"clusters\"    = \"RNA_clusters\",\n  \"ADT cluster\" = \"ADT_clusters\",\n  \"Cell label\"  = \"cell_label\",\n  \n  \"RNA UMI count\"     = \"nCount_RNA\",\n  \"Gene count\"        = \"nFeature_RNA\",\n  \"Percent mito UMIs\" = \"percent_mito\",\n  \"ADT UMI count\"     = \"nCount_ADT\",\n  \"Antibody count\"    = \"nFeature_ADT\",\n  \"HTO UMI count\"     = \"nCount_HTO\",\n  \"HTO count\"         = \"nFeature_HTO\"\n)\n\n# Create Cell Browser files for gene expression data\nmerged_so %>%\n  make_cellbrowser(\n    outdir      = \"cellbrowser\",\n    column_list = feats,\n    embeddings  = \"umap\",\n    project     = \"RNA\"\n  )\n\n\n\n\n\n# Create Cell Browser files for antibody data\nmerged_so %>%\n  make_cellbrowser(\n    outdir      = \"cellbrowser\",\n    column_list = feats,\n    embeddings  = \"adt_umap\",\n    project     = \"ADT\"\n  )\n\n\n\nBuild Cell Browser session\nTo build the cell browser session, install cbBuild. This tool will build the session using the configuration files generated in the previous step.\n\nmkdir -p cellbrowser/browser\n\ncbBuild \\\n  -i cellbrowser/RNA/cellbrowser.conf \\\n  -i cellbrowser/ADT/cellbrowser.conf \\\n  -o cellbrowser/browser \\\n  -p 8888\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-27T19:33:10-06:00",
    "input_file": {}
  }
]
