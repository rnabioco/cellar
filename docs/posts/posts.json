[
  {
    "path": "posts/2021-10-20-working-with-your-own-single-cell-data/",
    "title": "Working with your own single cell data",
    "description": "Guidelines for datasets to work with in the workshop, \ninformation on where to get public datasets, and \nexamples of how to load different data formats into R.",
    "author": [
      {
        "name": "Kent Riemondy",
        "url": {}
      }
    ],
    "date": "2021-10-20",
    "categories": [],
    "contents": "\nGuidelines for datasets\nWe ask that each workshop participant selects a dataset to analyze while taking the workshop. Each lecture will use standardized datasets, however we will set aside time for attendees to discuss analysis of their datasets with the instructors. Working through your own dataset (or a relevant published dataset) will reinforce concepts taught in class.\nIn this article we will discuss:\n- Guidelines and suggestions for the format of the dataset that you will analyze\n- Various data repositories and other sources of public datasets\n- Show examples of how to load various data formats into R for analysis with Seurat\nDataset format\nThe data that we will work with in the workshop will be count matrices. Count matrices are generally genes as rows and cells as columns, populated with read or UMI counts. These matrices are generated from pipelines such Cellranger (from 10x Genomics), or tools from academic labs such as Alevin (from the Patro lab), or Kallisto/Bustools (from the Pacther lab). These pipelines will align the raw FASTQ sequencing files, identify the barcodes associated with cell containing droplets, and output count matrices in various formats. Efficiently processing single cell datasets into count matrices generally requires more memory (RAM) and CPU power than is present on most laptops so we will not perform these steps in class. These steps are usually run on large compute clusters or on servers in the cloud. 10x Genomics offers a cloud service for running cellranger and the RBI has a pipeline for running cellranger on AWS.\nDataset size and complexity\nAs single cell datasets are continually growing in size (see article), so are the memory resources required for analyzing these datasets. A smaller dataset (e.g. ~5k cells) can be analyzed on a laptop with 8Gb of RAM without demanding too much memory. However, a dataset of ~50K cells generally maxes out the memory on a 2015 macbook pro with 16Gb of RAM.\nTo start analyzing single cell data, it is useful to learn the basics of the analysis working with 1 sample. However, 1 sample provides limited information, and is generally an insufficient dataset for learning new biology. Your dataset can therefore contain multiple samples, however this will increase the complexity of the analysis, particularly until we discuss methods for working with multiple samples in class 4.\nIdentifying public datasets\nIf you do not have a dataset in mind to analyze there are many sources.\n10x genomics 10x Genomics provides many datasets already processed through cellranger. You will need to register to gain access. The count matrix files to download, which contain only cell-associated barcodes, are called Feature / cell matrix (filtered).\nUCSC cellbrowser: This is collection of published datsets that have been already analyzed and placed into an interactive web browser. This is a nice resource as you can use to look at the data, and compare your own analysis to this data. When you select a dataset you can click the Data Download tab, and download the exprMatrix.tsv.gz file. Some datasets also provide seurat objects for download as well (e.g. human lung airway dataset). Note that the data included in the matrices is often already normalized, and not integer UMI counts. You will therefore want skip normalization in Seurat if you use these datasets.\nGene Expression Omnibus. Published single cell RNA-seq experiments should have their raw data deposited into GEO. Navigating GEO to find datasets is difficult and therefore it is better to first find a publication, then link to the publications dataset. A count matrix should be included as processed data with the submission, however not all datasets have these, and the data formats and naming conventions are not standardized. An example dataset from a mouse lung injury experiment is here, with the GSE113049_count_matrix.tsv.gz being the relevant UMI count matrix.\nBioconductor package: scRNAseq A curated selection of single cell datasets have been organized into a bioconductor pacakge called scRNAseq. These datasets are provided as SingleCellExperiment objects, which is the bioconductor data structure used for storing and working with single cell datasets. These can be easily converted to and from other data structures, such as Seurat, as shown in the “importing datasets into R” section.\n\n\nlibrary(scRNAseq)\nlistDatasets()\n\n\nDataFrame with 60 rows and 5 columns\n                 Reference  Taxonomy               Part    Number\n               <character> <integer>        <character> <integer>\n1   @aztekin2019identifi..      8355               tail     13199\n2   @bach2017differentia..     10090      mammary gland     25806\n3           @bacher2020low      9606            T cells    104417\n4     @baron2016singlecell      9606           pancreas      8569\n5     @baron2016singlecell     10090           pancreas      1886\n...                    ...       ...                ...       ...\n56    @zeisel2018molecular     10090     nervous system    160796\n57     @zhao2020singlecell      9606 liver immune cells     68100\n58    @zhong2018singlecell      9606  prefrontal cortex      2394\n59  @zilionis2019singlec..      9606               lung    173954\n60  @zilionis2019singlec..     10090               lung     17549\n                      Call\n               <character>\n1        AztekinTailData()\n2        BachMammaryData()\n3        BacherTCellData()\n4   BaronPancreasData('h..\n5   BaronPancreasData('m..\n...                    ...\n56     ZeiselNervousData()\n57   ZhaoImmuneLiverData()\n58   ZhongPrefrontalData()\n59      ZilionisLungData()\n60  ZilionisLungData('mo..\n\ncellXgene CellXgene is a visualation tool for single cell datasets developed by the Chan-Zuckerberg Institute. They also host a variety of public datasets, some of which can be downloaded as seurat Objects.\nPlease contact the instructors if you have any difficulties finding an appropriate dataset\nLoad data from the wild into R\nCellranger output\nCellranger produces many output files. The files in the filtered_feature_bc_matrix directory contain the count matrix for cell-associated barcodes in a special sparseMatrix format (matrix market format) that can be loaded into R using a few different packages.\n\n\n# read into R as a sparseMatrix\nmat <- Seurat::Read10X()\n# create a seurat object from the sparseMatrix\nCreateSeuratObject(mat)\n\n# alternatively, read into R as a SingleCellExperiment object for use with bioconductor\nDropletUtils::read10xCounts()\n\n\n\nFrom UCSC cellbrowser\nSome datasets provide a Seurat object as an .rds file. Download this file if provided. If not, then the gene expression data will also be provided in a tsv file called exprMatrix.tsv.gz.\n\n\n# to download and load an .rds file\ndownload.file(\"https://cells.ucsc.edu/mouse-dev-neocortex/seurat.rds\", \"seurat.rds\")\nseurat_object <- readRDS(\"seurat.rds\")\nseurat_object\n\n\n\n\n\n# to download and read in a .tsv file\n#download.file(\"https://cells.ucsc.edu/mouse-dev-neocortex/exprMatrix.tsv.gz\", \"data.tsv.gz\")\n\n# slow way\nmat <- read.table(\"data.tsv.gz\")\n# faster way, requires the data.table R package\nmat <- data.table::fread(\"data.tsv.gz\", sep = \"\\t\", data.table = FALSE)\n\n# move column \"gene\" to rownames and remove \nrownames(mat) <- mat[, 1]\nmat[, 1] <- NULL\n\n# convert to sparseMatrix to load into Seurat\nmat <- as.sparse(mat)\n\nCreateSeuratObject(mat)\n\n\n\nFrom GEO\nData in GEO has no standarized format, so you will need to adapt the approach based on the files provided. Generally we try to upload data in a .tsv,.csv or a sparseMatrix format.\nTo load a .tsv/.csv file from a GEO record you can use a similar approach as used for the .tsv file from the UCSC browser.\n\n\n# to download and read in a .tsv file\n#download.file(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE113nnn/GSE113049/suppl/GSE113049_count_matrix.tsv.gz\", \"data.tsv.gz\")\n\n# faster way, requires the data.table R package\nmat <- data.table::fread(\"data.tsv.gz\", sep = \"\\t\", data.table = FALSE)\n\n# move column \"V1\" to rownames and remove \nrownames(mat) <- mat[, 1]\nmat[, 1] <- NULL\n\n# convert to sparseMatrix to load into Seurat\nmat <- as.sparse(mat)\n\nCreateSeuratObject(mat)\n\n\n\nFrom the scRNAseq datasets\n\n\nlibrary(scRNAseq)\nlibrary(Seurat)\n# select a dataset from listDatasets()\n\n# assign to object to load into the rsession\nsce <- ZhongPrefrontalData()\n\n# convert to Seurat object from SingleCellExperiment\n# sometimes this approach will error out.\n# seurat_object <- as.Seurat(sce)\n# alternatively just extract the raw UMI counts matrix\nmat <- counts(sce)\nCreateSeuratObject(mat)\n\n\nAn object of class Seurat \n24153 features across 2394 samples within 1 assay \nActive assay: RNA (24153 features, 0 variable features)\n\nFrom the Alevin pipeline\nIf the data was generated by the Alevin pipelines you can use the tximport package to load the data into R. This process can be accelerated by also installing the fishpond package. Alevin will generate a file called quants_mat.gz which is a custom binary file with the counts matrix.\n\n\n#pseudocode\nfiles <- \"path/to/alevin/quants_mat.gz\"\ntxi <- tximport(files, type = \"alevin\")\nmat <- as.sparse(txi$counts)\nCreateSeuratObect(mat)\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-21T09:33:22-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-14-r-installation/",
    "title": "R installation",
    "description": {},
    "author": [],
    "date": "2021-10-15",
    "categories": [],
    "contents": "\nThis article will explain how to install R, Rstudio, and packages in R.If you are already familar with this material, skip to the Install packages for workshop section to see the packages that we will use in the workshop.\nDownload R\nDownload R from CRAN. Go to the cran homepage https://cran.r-project.org/. Select your operating system.\nMacOS\nSelect the newest R version, download the .pkg file, then open and install.\nWindows\nSelect the base link, then click download to download the .exe file. Open this file to install R.\nLinux\nIf you are on linux, then follow the documentation for your linux OS.\nDownload compiler tools\nMacOS\nYou may need to install the xcode command line tools if a package requires compilation. Open the Terminal from /Applications/Utilities/ (or use the search tool to search for terminal)\nType the following into Terminal:\nxcode-select --install\nPress “Install” and verify installation by typing into terminal:\ngcc --version\nWhich should print something similar to this:\n#' gcc (GCC) 4.8.5\n#' Copyright (C) 2015 Free Software Foundation, Inc.\n#' This is free software; see the source for copying conditions.  There is NO\n#' warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\nHere’s a youtube video explainer\nNext you need to install gfortran. Follow this link and go to the “INSTALL OS-SPECIFIC GFORTRAN BINARY” section. Select the download link based on your macOS version. This will supply an installer.\nWindows\nYou need to install Rtools from CRAN. Go to this link and download the exe installer for your OS: https://cran.r-project.org/bin/windows/Rtools/\nLinux\nYou probably have a compiler already?\nDownload Rstudio\nGo to the Rstudio website and download the installer for your OS.\nInstalling packages\nOnce you have R and Rstudio set up, open up rstudio, then we will install various packages.\nIn general there are 3 common places that you can get R packages from:\nCRAN, this is the official R package repository. CRAN has 16,000+ packages, including the tidyverse (ggplot2, dplyr, etc) and Seurat. Packages are installed using the install.packages() function. A successful install only needs to be done once.\nIn your console execute the following:\ninstall.packages(\"tidyverse\")\ninstall.packages(\"Seurat\")\nTest package installation once complete by loading the package(s)\nlibrary(tidyverse)\nlibrary(Seurat)\nBioconductor, which generally has bioinformatics related packages, such as clustifyr, DESeq2, ComplexHeatmap, etc.\nTo install bioconductor packages you should use the CRAN package BiocManager. BiocManager has a function called install() to install bioconductor packages. For example to install clustifyr\ninstall.packages(\"BiocManager\")\nlibrary(BiocManager)\ninstall(\"clustifyr\")\n# or equivalently you could run BiocManager::install(\"clustifyr\")\nGithub hosts open-source code from millions of projects. R packages hosted on github can be installed using the remotes package. Presto or djvdj are examples of single cell RNA-seq analysis packages on github. You’ll need to find the organization name and the repository name on github to install.\ninstall.packages(\"remotes\")\nremotes::install_github('rnabioco/djvdj')\nremotes::install_github('immunogenomics/presto')\nInstall packages for workshop\nWe will use the following packages:\nFrom CRAN:\n- tidyverse\n- Seurat\n- rmarkdown\n- cowplot\n- colorblindr\n- markdown\n\n\ninstall.packages(c('tidyverse',\n                   'rmarkdown',\n                   'Seurat',\n                   'cowplot',\n                   'colorblindr',\n                   'markdown'))\n\n\n\nFrom Bioconductor:\n- ComplexHeatmap\n- scran\n- scDblFinder\n- limma\n- clustifyr\n- slingshot\n- tradeSeq\n\n\nBiocManager::install(c('ComplexHeatmap', \n                       'scran',\n                       'scDblFinder',\n                       'limma',\n                       'clustifyr',\n                       'slingshot',\n                       'tradeSeq'))\n\n\n\nFrom github:\n- destiny (hosted on bioconductor typically but not building correctly right now)\n\n\nremotes::install_github('theislab/destiny')\n\n\n\nIf you’d like to test the installation, please run this test Rmarkdown hosted on github.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-20T16:10:11-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-15-running-rrstudio-with-docker/",
    "title": "Running R/Rstudio with docker",
    "description": "In this post we will discuss how to use docker\nto run R and Rstudio in a standardized environment.",
    "author": [
      {
        "name": "Kent Riemondy",
        "url": {}
      }
    ],
    "date": "2021-10-15",
    "categories": [],
    "contents": "\nWe’ve built a docker image that contains the R packages used in the workshop and made it available on dockerhub. This image can be used if you have issues installing the recommended R packages.\nWhat is docker?\nDocker is an application that allows identical software environments (called images) to be run in different operating systems (MacOS, Linux or Windows). The standardized software environment (programs, data, and configuration) takes away the headache of trying to install and maintain software. Practically using docker also enforces a reproducible analysis environment.\nIn this post we will discuss the basics of how to:\ninstall docker\nrun docker on the command-line/terminal\nrun a docker container containing R, Rstudio\nrun a docker container for this workshop that contains a variety of single cell packages\nInstall docker\nMacOS: Install Docker desktop here: https://docs.docker.com/desktop/mac/install/\nWindows: If you do not have the WSL enabled or installed, following the instructions here: https://docs.microsoft.com/en-us/windows/wsl/install\nThen download and install Docker desktop for windows: https://docs.docker.com/desktop/windows/install/\nOpen the docker application to confirm installation.\nHow to run a docker container\nA docker image refers to the standarized software environment. A docker container is the copy of the image that is downloaded and run on a specific computer.\nIf the docker application is running, then you should be able to run a docker container in the command line. Open up Terminal in macOS or PowerShell in windows.\nIf you run the following command, an image with R and Rstudio installed (rocker/tidyverse) will be downloaded from dockerhub and activated.\ndocker run --rm -e PASSWORD=rna -p 8787:8787 rocker/tidyverse\nWe’ll explain the other command arguments in a moment.\nYou’ll see some messages that will look something like this:\nUnable to find image 'rocker/tidyverse:latest' locally\nlatest: Pulling from rocker/tidyverse\n...\n...\nStatus: Downloaded newer image for rocker/verse:latest\n[s6-init] making user provided files available at /var/run/s6/etc...exited 0.\n[s6-init] ensuring user provided files have correct perms...exited 0.\n[fix-attrs.d] applying ownership & permissions fixes...\n[fix-attrs.d] done.\n[cont-init.d] executing container initialization scripts...\n[cont-init.d] userconf: executing...\nskipping /var/run/s6/container_environment/HOME\nskipping /var/run/s6/container_environment/PASSWORD\nskipping /var/run/s6/container_environment/RSTUDIO_VERSION\n[cont-init.d] userconf: exited 0.\n[cont-init.d] done.\n[services.d] starting services\n[services.d] done.\nAfter running this command an rstudio instance will be running on your computer that you can access through your web browser. Open a browser and enter http://, followed by your ip address, followed by :8787. In you are on a linux or MacOS machine you can navigate to http//localhost:8787. If you do not know the IP address you can find it in a few ways.\nIf you select the container in the docker desktop app, you can directly open the container in a browser by clicking the open in browser button.\n\n\n\nYou can obtain the IP address from the command line.\nGet list of all of your containers using docker ps\ndocker ps\nCONTAINER ID   IMAGE          COMMAND   CREATED          STATUS          PORTS                                       NAMES\nd2629b78er4f   rocker/verse   \"/init\"   14 minutes ago   Up 14 minutes   0.0.0.0:8787->8787/tcp, :::8787->8787/tcp   blissful_jepsen\nThen use docker inspect get ip address using the value found under “CONTAINER ID”\ndocker inspect d2629b78er4f\nJust get the ip-address\ndocker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' d2629b78er4f\nNavigate to http://Your.I.p.Address:8787\nYou should see a Rstudio login page\n\n\n\nLogin to rstudio with username rstudio and password rna. You should see Rstudio running in your browser.\n\n\n\nOnce you are done playing around in rstudio you can stop the container by terminating the process in your terminal:\nGo back to your terminal and run CTRL + C in macOS or linux, or Ctrl+Break in Windows\nYou’ll see a few more messages, then the command will exit back to your prompt\ns6-finish] waiting for services.\n[s6-finish] sending all processes the TERM signal.\n[s6-finish] sending all processes the KILL signal and exiting.\n$\nWhen you initiated the docker container we used the following command:\ndocker run --rm -e PASSWORD=rna -p 8787:8787 rocker/tidyverse\nThe --rm is a special flag that tells docker to delete the container after exiting. You can verify this occurred by looking at your containers in Docker Desktop or by runnning docker ps on the command line.\nThe --rm option is a good way to start working with docker. If you don’t include this a new container will be made each time you execute docker run unless you provide different flags. This can quickly take up disk space if you are not careful so we recommend that you use --rm for now. The other advantage is this approach ensures that your R environment is restored to a clean environment each time you start the container.\nThe -e PASSWORD=rna parameter specified that the password for logging into rstudio should be rna.\nThe -p 8787:8787 parameter specified that Rstudio should be served on the 8787 port.\nHow to use and create files on your local computer\nYou may have noticed that you do not have access to local files in the rstudio instance by default. This is expected behavior as the docker container exists in an isolated environment for your local computer.\nIf you want to provide rstudio access to a local directory to allow reading and writing local files do the following:\nFind the path to a directory on your computer e.g. for the desktop on macOs use ~/Desktop or for documents in windows C:\\Documents\nadd the -v parameter which has the syntax -v /path/to/local/directory:/path/in/container. Because we are using rstudio, if we put files into the container at /home/rstudio, they will be visible to rstudio.\nTry it out: Here I am making my a class directory on my desktop (on a macOS) visible to rstudio. The class directory has 1 file called hello-world.txt.\ndocker run --rm -v ~/Desktop/class:/home/rstudio -e PASSWORD=rna -p 8787:8787 rocker/tidyverse\nIn Rstudio I can now see the hello-world.txt file, and if I make a new file in R called docker-file.txt, it will now be visible on my local computer, and persist after I exit docker.\n\n\n\nSimilarly you could write a R script or Rmarkdown document, run it in rstudio, then save the script into your local files for future reuse.\n\n\n\nUsing docker for workshop\nWe have a docker image available on dockerhub that includes the packages that will be used in the class.\nrstudio-scrnaseq\nYou can use this image in the same manner as above, instead using kenter/rstudio-scrnaseq.\nTry it out:\ndocker run --rm -e PASSWORD=rna -p 8787:8787 kenter/rstudio-scrnaseq\nWhen you open rstudio you should be able to load Seurat and other single cell packages. We’ve also included a test.Rmd document that lists and loads all of the relevant installed packages, and tests basic Seurat commands.\nAdditional resources\nIf you’ve never used docker here are some useful tutorials on using docker:\nhttps://bioconductor.org/help/docker/#quickstarthttps://jsta.github.io/r-docker-tutorial/https://replikation.github.io/bioinformatics_side/docker/docker/#important-commands\n\n\n\n",
    "preview": "posts/2021-10-15-running-rrstudio-with-docker/img/open-in-browser.png",
    "last_modified": "2021-10-20T16:10:11-06:00",
    "input_file": {}
  }
]
